repo,sha,author,date,message,additions,deletions,total_changes
tensorflow/tensorflow,c56972459d22e3ddc0c0e0ac04ae85d0b33270f9,Ionel Gog,2025-07-12T00:52:53Z,[IFRT IR] Use the auto-generate pass creation functions rather than custom defined funcs.  PiperOrigin-RevId: 782172174,147,320,467
tensorflow/tensorflow,f1be0a349603f317bc8d019cc3f51dd15f956bf6,Xinxin Mo,2025-07-12T00:00:11Z,[xla] Add back test targets in //xla/tools/hlo_diff on CI because the service outage  errors (https://github.com/openxla/xla/actions/runs/16007180610/job/45156461568)  have been fixed in https://github.com/openxla/xla/pull/28465.  Reverts f590575b0ed93e703ec30b29f815bf5077ce5468  PiperOrigin-RevId: 782158057,39,42,81
tensorflow/tensorflow,6bf187731ee3f19ad358a7b62e251b934657a68d,Shahriar Rouf,2025-07-11T23:57:09Z,Optimize `GlobalDecreasingSizeBestFitHeap::MakeFreeChunks` by 1.2X to 1.4X.  `BM_GlobalDecreasingSizeBestFitHeap` benchmark is optimized by up to 1.17X.  PiperOrigin-RevId: 782157151,69,71,140
tensorflow/tensorflow,8abac72e9a1538f6e2a3e0f58b2ebddb059f6d6f,Sean Talts,2025-07-11T23:55:55Z,[XLA:CPU] Use templated intrinsic helpers for log1p and fix intrinsic name.  PiperOrigin-RevId: 782156735,24,28,52
tensorflow/tensorflow,71b19d1848d1b413479083e2b450554207a2a134,Sandeep Dasgupta,2025-07-11T23:24:40Z,[Phase Compilation] Part-4: Add C++ layers to test and interact with C PJRT API.  PiperOrigin-RevId: 782147317,694,23,717
tensorflow/tensorflow,1b87c38dda842bedb5b01b7592b83292d7252cb3,Siqiao Wu,2025-07-11T22:47:53Z,Fix sink invariant in tf.ifregion.  PiperOrigin-RevId: 782135828,5,1,6
tensorflow/tensorflow,ce11edc4ef3e1e7a9cf75885a867b892d966d7c6,A. Unique TensorFlower,2025-07-11T22:18:11Z,Reverts e4fccd6471306e8b4d4012a423376c170e6a6301  PiperOrigin-RevId: 782126042,37,109,146
tensorflow/tensorflow,c3fe34a8b0e65586eff8ed6719e42da3120e785d,David Dunleavy,2025-07-11T21:16:03Z,Now that we don't steal from `tensorflow/third_party` don't do any post hoc Copybara for TensorFlow builds  (*) Except for `tensorflow/third_party/py`  PiperOrigin-RevId: 782106216,0,62,62
tensorflow/tensorflow,e1c72193da6cc88e11dbee81cf5fe19187ff1312,David Dunleavy,2025-07-11T20:39:51Z,Migrate uses of `XLA_TEST_BACKEND` macros to use utilities in `xla_test_backend_predicates.h`  Reverts c9ca1c456e1032ba1e4d728fdda68bf9a46b4f92  PiperOrigin-RevId: 782094674,50,52,102
tensorflow/tensorflow,976bca01cc803767a0dcba39ab4ca818d98639b5,Kevin Gleason,2025-07-11T20:35:05Z,[SDY] Refactor MHLO dependencies where possible  PiperOrigin-RevId: 782093218,10,9,19
tensorflow/tensorflow,04b16a94c8fbe9b4a5366bfe3ced693b09b4f4c2,Eugene Zhulenev,2025-07-11T20:35:03Z,[xla:codegen] Start migrating Ldexp to Intrinsic declaration  PiperOrigin-RevId: 782093202,53,26,79
tensorflow/tensorflow,e9a2f9de8dc960f6064c2acc518072c170f7e265,A. Unique TensorFlower,2025-07-11T20:16:48Z,[XLA] Refactor HloDCE for improved readability.  A minor modification is also made for dangling computations where `changed` is only set to `true` when a computation is actually removed to account for the possibility that a dangling computation might be filtered by execution_threads.  PiperOrigin-RevId: 782086875,214,106,320
tensorflow/tensorflow,e4fccd6471306e8b4d4012a423376c170e6a6301,Eugene Zhulenev,2025-07-11T19:57:16Z,[xla:cpu] Move memory allocation functions to tf2xla  PiperOrigin-RevId: 782080412,109,37,146
tensorflow/tensorflow,a5e5df512a42756cc9ae7cc7b9144672e922c4b0,A. Unique TensorFlower,2025-07-11T19:52:08Z,Add traceme for IFRT executable launch  PiperOrigin-RevId: 782078942,19,11,30
tensorflow/tensorflow,c386cae688f368970ffb0f22866b2af8f1e8fe62,Sean Talts,2025-07-11T19:48:55Z,[XLA:CPU] Refactor Rsqrt intrinsic with new UnaryIntrinsicBase.  PiperOrigin-RevId: 782077991,125,54,179
tensorflow/tensorflow,2a9a72198a3e411c5eac071c5f5abc29d84efa5c,Zac Mustin,2025-07-11T18:19:38Z,Fix clang-tidy errors in `pjrt_c_api_helpers.cc`.  PiperOrigin-RevId: 782047204,3,2,5
tensorflow/tensorflow,8229468def07caf1c7fcf4634cf79f97ef4c2fa4,Alex Pivovarov,2025-07-11T17:36:34Z,"[Autotuner] Add block level emitter backend for Triton fusion.  This change introduces the Triton block-level fusion emitter backend, which enables autotuning of tile configurations for custom Triton fusions in XLA.  This backend implements the following core interfaces: - GetSupportedConfigs: Enumerates all supported combinations of tile sizes for the output tensors. The generated configs can be used during autotuning to explore different performance candidates. (will be added in the next PR) - GetDefaultConfig: Provides a default tile configuration for a given Triton fusion, used as a fallback when no tuning data is available. - ApplyConfig: Applies a selected block-level fusion configuration to a Triton fusion instruction by updating its GpuBackendConfig. (will be added in the next PR)  PiperOrigin-RevId: 782032163",583,0,583
tensorflow/tensorflow,5615e58396c085e380de493e1c294195b6dedfe1,Mikhail Goncharov,2025-07-11T16:47:19Z,[XLA:GPU] flag to control nested gemm fusion  For more granular control over generic triton emitter.  That replaces the binary `xla_gpu_unsupported_enable_generic_triton_emitter_for_gemms`.  Sample usage `--xla_gpu_unsupported_generic_triton_emitter_features=enable_nested_gemm`  Drive by update of the comment on xla_gpu_enable_llvm_module_compilation_parallelism.  PiperOrigin-RevId: 782014919,423,75,498
tensorflow/tensorflow,767aba953a18097b5ded1a10d72fa658de5b32b8,A. Unique TensorFlower,2025-07-11T15:56:30Z,Reverts 9b88203f15334e7e779bb2b3200448a07ad0245b  PiperOrigin-RevId: 781999343,6,105,111
tensorflow/tensorflow,495583c4e765b39da4df68d82539264ea148c3dc,spiao,2025-07-11T15:31:02Z,"PR #28314: [ROCm] added allreduce kernel registration  Imported from GitHub PR https://github.com/openxla/xla/pull/28314  added the missing allreduce kernel registration on ROCm  it fixes all the failed AllReduceTest/AllReduceTest.* in collective_ops_e2e_test. e.g. `bazel-bin/xla/tests/collective_ops_e2e_test_amdgpu_any --gtest_filter=AllReduceTest/AllReduceTest.AsyncAllReduce_F32_2GPUs/async_one_shot`  @xla-rotation could you review my PR, please? Copybara import of the project:  -- 6517bd88291374e9754838ac82a5d58fe4386c8d by songlin <Songlin.Piao@amd.com>:  adapt allreduce kernel registration in rocm  -- 6e255aa68932a42964c048dd24ecd944a7dbf0c9 by songlin <Songlin.Piao@amd.com>:  adapt to get rid of macro usage  -- af96c9743ad6abbe323709d1721c013abb84e206 by songlin <Songlin.Piao@amd.com>:  make PutSignalFlag and WaitSignalFlag as templates with specialization for ROCm and CUDA  Merging this change closes #28314  PiperOrigin-RevId: 781992142",186,41,227
tensorflow/tensorflow,6503034148ab3c0469a32d20b9a3ea397457a8f8,Christian Sigg,2025-07-11T13:39:44Z,"[Triton] Add triton squeeze dims pass  This pass removes size-1 dimensions from tensors to generate faster code through Triton.  - `squeeze_dims` ops are extracted from each unit dimension of `tt.reshape`. - A series of patterns push `squeeze_dims` up through the graph, past element-wise ops, broadcast, transpose, join, reduce. - `squeeze_dims` are folded into `tt.load` and `tt.expand_dims`, or converted back to `tt.reshape`.  PiperOrigin-RevId: 781962093",752,4,756
tensorflow/tensorflow,8f1a89fbc96f41cbb5112d35ee655dbab53a1456,A. Unique TensorFlower,2025-07-11T13:14:28Z,Move llvm() and llvm_setup() calls down one workspace*.bzl file.  This makes XLA consistent with TF.  PiperOrigin-RevId: 781955402,6,7,13
tensorflow/tensorflow,f4cc3725c3a570504ac9cb369dc6fb8e25316159,Karlo Basioli,2025-07-11T12:54:14Z,Reverts 55a3ba02a6b51595dea5efaf3dce7e44ab2409c1  PiperOrigin-RevId: 781950054,11,0,11
tensorflow/tensorflow,934774e8f6bf7ce74e2c1597c4ded553dbbcfdba,Adrian Kuegel,2025-07-11T12:44:43Z,"Remove dead code from TuplePointsToAnalysis (NFC).  While there, also fix a few ClangTidy warnings.  PiperOrigin-RevId: 781947527",10,89,99
tensorflow/tensorflow,ef6a3d4952cf23ff4c998b7a5c7a3ddc1b8edec4,Will Froom,2025-07-11T11:18:56Z,[XLA:CPU] Add log1p math lib function.  PiperOrigin-RevId: 781926524,433,49,482
tensorflow/tensorflow,82b30799748b9a1e3735c1c4f9dbd878d4aab3e3,Adrian Kuegel,2025-07-11T10:01:24Z,Remove mutable buffer accessor methods from HloAliasAnalysis (NFC).  All current users don't actually need mutable access.  PiperOrigin-RevId: 781905323,3,17,20
tensorflow/tensorflow,55918edf5b3e917d9f5e183a35af59ae2cb43caf,Kanish Anand,2025-07-11T09:53:56Z,Use unused sharding variable  PiperOrigin-RevId: 781903248,1,2,3
tensorflow/tensorflow,0104643a0f902266b42d43471a3bc90d648844fb,Allan Renucci,2025-07-11T09:48:54Z,"[XLA:GPU] Enable heuristic based synchronous and pipelined collective combining by default.  This change only takes effect if the user does not set the `xla_gpu_{all_reduce,all_gather,reduce_scatter}_combine_threshold_bytes` flags.  PiperOrigin-RevId: 781902147",1,1,2
tensorflow/tensorflow,c8be60b77f12e880d1fa462b548d348e4f3dd616,Will Froom,2025-07-11T09:15:57Z,[XLA:CPU] Fix race condition in LowerXlaMathLibPass.  PiperOrigin-RevId: 781894153,2,2,4
tensorflow/tensorflow,60f06ae24cba4d76da940cc6fdb55e9c5647793f,A. Unique TensorFlower,2025-07-11T09:04:50Z,compat: Update forward compatibility horizon to 2025-07-11  PiperOrigin-RevId: 781890727,1,1,2
tensorflow/tensorflow,e819acf37f8d4d26d0f400c40f35e8d9b94a729d,A. Unique TensorFlower,2025-07-11T09:02:49Z,Update GraphDef version to 2285.  PiperOrigin-RevId: 781890029,1,1,2
tensorflow/tensorflow,8335c0a33f0a5c8a436a032e50963db6df289690,Will Froom,2025-07-11T08:39:53Z,[XLA:CPU] Use xla intrinsic f32 -> bf16 conversion.  PiperOrigin-RevId: 781883075,63,51,114
tensorflow/tensorflow,6253ee144010e0a6dcef1d0413ea8b923a6439b4,A. Unique TensorFlower,2025-07-11T08:10:33Z,Automated Code Change  PiperOrigin-RevId: 781875010,1,1,2
tensorflow/tensorflow,569724c4412d49d55302f6b0208cb09e8935bc76,Yunjie Xu,2025-07-11T07:21:10Z,No public description  PiperOrigin-RevId: 781861930,3,0,3
tensorflow/tensorflow,cef9b5d8d0ad1d86b3b8d816446f4b86c675aa01,A. Unique TensorFlower,2025-07-11T07:08:27Z,Automated Code Change  PiperOrigin-RevId: 781858106,2,2,4
tensorflow/tensorflow,f202888354720561cff8bcef82a77b368ac3d3dd,A. Unique TensorFlower,2025-07-11T06:31:37Z,"Make `Execute*()` `const` for `*Executable` classes.  We cache `*Executable` objects to reuse compilation results. This means that we may call `Execute*()` on such cached objects multiple times and expect that the calls won't affect the objects' behaviors. In other words, `*Executable()` should be `const`. Marking them `const` prevents the code from accidentally mutating cached executables and causing bugs.  PiperOrigin-RevId: 781847420",74,54,128
tensorflow/tensorflow,55a3ba02a6b51595dea5efaf3dce7e44ab2409c1,Eugene Zhulenev,2025-07-11T06:13:32Z,[xla:cpu] Remove XLA_ALIGN macro  PiperOrigin-RevId: 781843003,0,11,11
tensorflow/tensorflow,418d081cc8f8c5f28370236681f0f65bcd689eae,A. Unique TensorFlower,2025-07-11T05:35:13Z,Automated Code Change  PiperOrigin-RevId: 781832145,0,3,3
tensorflow/tensorflow,c9ca1c456e1032ba1e4d728fdda68bf9a46b4f92,A. Unique TensorFlower,2025-07-11T05:19:44Z,Reverts 1d1309b2712b001b325962ee76972f14681913da  PiperOrigin-RevId: 781828585,52,50,102
tensorflow/tensorflow,83290cdd2876d8862a1c53c7e52d242569f9cfa7,A. Unique TensorFlower,2025-07-11T04:24:53Z,Automated Code Change  PiperOrigin-RevId: 781814264,4,0,4
tensorflow/tensorflow,64e05953b9e35fe960442d65b2e5a0ed03b79084,Julia Guo,2025-07-11T01:31:28Z,[XLA:benchmarks] Remove comments related to testing  PiperOrigin-RevId: 781766386,0,4,4
tensorflow/tensorflow,5cd3ff240232fb85faf67bd76c86e773ce68273d,David Dunleavy,2025-07-11T01:19:23Z,Move `tensorflow/third_party/llvm` to `xla/third_party/llvm`  PiperOrigin-RevId: 781763691,8,8,16
tensorflow/tensorflow,1d1309b2712b001b325962ee76972f14681913da,David Dunleavy,2025-07-10T23:57:27Z,Migrate uses of `XLA_TEST_BACKEND` macros to use utilities in `xla_test_backend_predicates.h`  PiperOrigin-RevId: 781737406,50,52,102
tensorflow/tensorflow,2b3356a042200027dfe534b606a8e25c2319f8e9,Niklas Vangerow,2025-07-10T23:18:11Z,Reduce likelihood of collisions in precompilation using Default print options.  PiperOrigin-RevId: 781724957,2,2,4
tensorflow/tensorflow,9b88203f15334e7e779bb2b3200448a07ad0245b,Michael Kuperstein,2025-07-10T23:08:51Z,[XLA] CSE collectives with different channel IDs when it's safe to do so.  PiperOrigin-RevId: 781721931,105,6,111
tensorflow/tensorflow,10205f8bf7c52d9af67be6cb34d10934c3eb205f,Bixia Zheng,2025-07-10T22:29:00Z,"[XLA] Implement operand-to-result layout propagation for custom calls  This allows propagating layout from an operand to the result, based on output-to-operand-alias information.  PiperOrigin-RevId: 781706746",88,1,89
tensorflow/tensorflow,06691176f4f4ffd96b76ac5a157fa38662e1dbee,Bixia Zheng,2025-07-10T22:09:14Z,[xla:gpu] Handle buffer related custom calls.  Add executable tests.  PiperOrigin-RevId: 781699123,129,2,131
tensorflow/tensorflow,e3a0ebde0d387f408ca08d3417f17e8ed1656339,Terry Heo,2025-07-10T21:23:58Z,Refactor delegate_test_util to simpler to use  This change improves the usability of the test_utils::SimpleDelegate utility by replacing the long list of boolean parameters with readable Options enum.  PiperOrigin-RevId: 781681590,126,115,241
tensorflow/tensorflow,aa1ab63fea901c112c25f5ebc4b3bbe9f8c73492,Will Froom,2025-07-10T20:53:40Z,[XLA:CPU][XLA:GPU] use correct alignment on transfer_write  PiperOrigin-RevId: 781669338,36,3,39
tensorflow/tensorflow,68d963e4a3f5a2153b5d01959b26d8664604bfa6,Majid Dadashi,2025-07-10T20:52:13Z,Fix bounds check for input offsets in quantized ops.  The inputs offsets are negative of the zero points so that should be their acceptable ranges.  PiperOrigin-RevId: 781668766,3,3,6
tensorflow/tensorflow,9bb1c74092011253c1d7ef869d4517dcd98c1cfb,A. Unique TensorFlower,2025-07-10T20:20:11Z,Turn off auto sharding stablehlo test.  PiperOrigin-RevId: 781656212,4,0,4
tensorflow/tensorflow,b26ceb28ed5b7eb66a5b7bb30e46afd7245c1faf,A. Unique TensorFlower,2025-07-10T19:39:50Z,Return DeadlineExceededError when getting handler from the pool times out.  PiperOrigin-RevId: 781641050,6,3,9
tensorflow/tensorflow,c76e9691e36e2d06a0aedb7886754967a42a6f6f,Will Froom,2025-07-10T19:21:17Z,[XLA:CPU] Add expansion of math.cbrt to pow  PiperOrigin-RevId: 781634299,47,1,48
tensorflow/tensorflow,5de05ad1f2871e2f82ab4d97aefc8b3854536ef7,Eugene Zhulenev,2025-07-10T18:55:21Z,[xla:codegen] Use FpTrunc::CreateDefinition to create xla.fptrunc definitions  PiperOrigin-RevId: 781624007,69,79,148
tensorflow/tensorflow,5619e535abd9520f8ff2ac5053d4d64cb078e4dc,Daniel Sosa,2025-07-10T18:51:38Z,Internal CI changes.  PiperOrigin-RevId: 781622283,1,1,2
tensorflow/tensorflow,6590dd7b8ca25e54c9ad6022114104ab201b30b6,Allan Renucci,2025-07-10T18:50:50Z,[XLA:GPU] Restrict heuristics based collective combiners to multi-host topology.  PiperOrigin-RevId: 781621893,8,1,9
tensorflow/tensorflow,38f76cbd922507e6a110ead117e93d450bd24e62,A. Unique TensorFlower,2025-07-10T18:49:08Z,Set XNN_FLAG_SLINKY_NO_CHECKS in xnn_fusion_thunk.  PiperOrigin-RevId: 781621183,8,4,12
tensorflow/tensorflow,d42d48b38075f789d701e05fa355fc5b2d21161a,Michael Kuperstein,2025-07-10T18:48:10Z,"[XLA] Factor out the ""do channel IDs carry semantic information"" check.  Note that `!use_spmd_partitioning_` is likely not the right condition, but I want this to be a pure refactor first and we can adjust the condition later.  PiperOrigin-RevId: 781620792",8,1,9
tensorflow/tensorflow,d7ae23d46cbc35ae20122383cf87293eb54fcccb,A. Unique TensorFlower,2025-07-10T18:35:44Z,Removed an error emission for a failed legalization.  PiperOrigin-RevId: 781616159,2,3,5
tensorflow/tensorflow,8b23732985283ac1a309f7cdb1f5459f60a47cf0,Bryan Massoth,2025-07-10T18:31:26Z,Add StatType for input pipeline traces.  PiperOrigin-RevId: 781614433,2,0,2
tensorflow/tensorflow,a63b460fc79e4cd6d996a5f43c328da8374e90fe,Will Froom,2025-07-10T17:30:01Z,[XLA:CPU] Add conversion from math.erf f64 to libm call  PiperOrigin-RevId: 781590068,86,11,97
tensorflow/tensorflow,30b848e73c2c86f464d18ac0f3626725fc51b5a8,Sean Talts,2025-07-10T17:22:58Z,"[XLA:CPU] Implement rsqrt with Newton-Raphson refinement.  Design decisions: - rsqrt is the first and perhaps only function that uses x86-specific intrinsics.   - We choose the intrinsics we need based on the requested floating point type and vector width.   - This means we outsource cpu feature detection elsewhere (it will go in the VecDescs generation function). - Only some vector width + fp types are competitive with 1 / rsqrt.   - We will benchmark on the main architectures to see where to do the replacement   - We will add a more holistic hlo fusion benchmark with add, mul, rsqrt to better approximate the cost of the division op.  ``` ------------------------------------------------------------------------------------------------ Benchmark                                                      Time             CPU   Iterations ------------------------------------------------------------------------------------------------ BM_RsqrtVectorized<4, F32, kRsqrt>/process_time           310412 ns       310495 ns         2271 BM_RsqrtVectorized<4, F32, kOneOverSqrt>/process_time     222650 ns       222991 ns         3125 BM_RsqrtVectorized<8, F32, kRsqrt>/process_time           312053 ns       312342 ns         2243 BM_RsqrtVectorized<8, F32, kOneOverSqrt>/process_time     352200 ns       352706 ns         2010 BM_RsqrtVectorized<8, F64, kRsqrt>/process_time           409729 ns       409382 ns         1714 BM_RsqrtVectorized<8, F64, kOneOverSqrt>/process_time    1178363 ns      1177512 ns          582 ```  PiperOrigin-RevId: 781587256",753,63,816
tensorflow/tensorflow,af757a4e6335119d22313de292d6050b45d6644b,A. Unique TensorFlower,2025-07-10T17:19:50Z,Eliminate sdy.data_flow_edge before Shardy->HLO transformation.  PiperOrigin-RevId: 781585969,43,2,45
tensorflow/tensorflow,678e12e32cdfa8705433035feee761755f4139a6,jparkerh,2025-07-10T17:15:26Z,"Example Extension with cpp dependency injection  Trying to come up with a cleaner way to do dependency injection inside an extension that adds minimal additional apis for those who want to implement directly at the C api. This mechanism keeps the C API cleaner for pure C implementers, but also allows for implementation at CPP for easy composability/testability etc.  PiperOrigin-RevId: 781584176",490,2,492
tensorflow/tensorflow,1b5a11a71805ff446673bcacb14c4067d6bb652d,Eugene Zhulenev,2025-07-10T16:23:00Z,[xla:codegen] Use FpTrunc::Name to generate implementation  PiperOrigin-RevId: 781563253,10,23,33
tensorflow/tensorflow,579b12fa85995c5ad3daf0fdfc2245b328d7a8cd,Jeffrey A. Dean,2025-07-10T16:16:50Z,Added benchmark for GlobalDecreasingSizeBestFitHeap that exercises MakeFreeChunks (indirectly by calling Alloc and Free to exercise different #s of allocated chunks and then calls Finish()).  PiperOrigin-RevId: 781561398,35,0,35
tensorflow/tensorflow,82f48a1d8962fcb5c2ffcf73f94c519902d0ecde,Allan Renucci,2025-07-10T16:07:47Z,Fix formatting in `gpu_compiler.cc`.  PiperOrigin-RevId: 781558486,11,11,22
tensorflow/tensorflow,4d9716db2f4f941913a4fa9bda25e8bda1fd4afc,David Pizzuto,2025-07-10T16:00:38Z,"hlo_runner_agnostic_test_base: Compile both modules before executing either.  RunAndCompareTwoModules compiles and executes two modules, and if we trigger an execution before we compile the second then we can't trace the compilations for caching purposes.  Unfortunately RunAndCompareTwoModulesReplicated doesn't have a nice way to do the same thing, as decomposing it needs the fundamentally-hardware-dependent concept of the device assignment.  PiperOrigin-RevId: 781555806",13,5,18
tensorflow/tensorflow,48f9ffe09b8984ee0d3c1b72ae127c05e43723f4,Karlo Basioli,2025-07-10T15:32:50Z,[XLA][host_offloading] Open source host offloading executable.  PiperOrigin-RevId: 781547064,1537,0,1537
tensorflow/tensorflow,8b2851dc818bb467b0793e4ff8863882d7887c9b,Vlad Sytchenko,2025-07-10T14:31:29Z,[XLA] Make CSE customizable  PiperOrigin-RevId: 781526169,158,40,198
tensorflow/tensorflow,a3bfe52f6bee06fbced74f06ce6d427d2aa81348,Bixia Zheng,2025-07-10T13:43:44Z,"[xla:layout_assignment] Support buffer types.  Change Shape and ShapeUtil to support the query and modification to the layout of the array storage inside a buffer type.  Enhance layout assignment to support buffer types. There are still problems, such as supporting operand_layout_constraints in layout assignment, which will be addressed in CLs in the sequence.  PiperOrigin-RevId: 781512370",224,84,308
tensorflow/tensorflow,7dd8ff2aedae44af5c8fcfc3b56793b9bbd15ef9,Adrian Kuegel,2025-07-10T13:33:52Z,"Make mutable GetValueSet private (NFC).  Remove the unused variant of this method. Also rename it to GetMutableValueSet to avoid compile errors, somehow the compiler cannot figure out that it can use the non-mutable method in certain cases.  PiperOrigin-RevId: 781509391",37,36,73
tensorflow/tensorflow,ae414b6ae0dc2bb8073f16ab59dbbefa43043a9b,Aliia Khasanova,2025-07-10T13:26:33Z,[XLA:GPU] Remove prevent mmav3 loop unrolling pass for triton.  This pass was added as a workaround for PTXAS and should have been fixed by NV a long time ago. The benchmarks look good overall and don't introduce regressions on the important models  PiperOrigin-RevId: 781507284,0,224,224
tensorflow/tensorflow,8e79172949070a3e8bc3b06a1fec4518951393a2,A. Unique TensorFlower,2025-07-10T12:37:07Z,Only set `local_device_name_` once in the constructor to avoid data races  PiperOrigin-RevId: 781493257,2,2,4
tensorflow/tensorflow,9cc442f8ef24b9a55f60a194f31d03e38c64d11d,Will Froom,2025-07-10T12:21:27Z,[XLA:CPU] Add flag to flatten the call graph after fusion.  PiperOrigin-RevId: 781489163,25,4,29
tensorflow/tensorflow,32b583973739f3f4aa09b7a5136de645fc59ada6,Henning Becker,2025-07-10T11:57:51Z,Introduce ELF section extraction code  This adds code that can extract the contents of a section from an ELF file.  For convenience reason the function also supports static libraries which are GNU AR archives containing multiple ELF files. In that case the function returns the first found matching ELF section.  The code can be used to extract .nv_fatbin sections from CUDA libaries and will be needed to serialize CUDA C++ kernels into serialized GPU programs.  PiperOrigin-RevId: 781482184,888,0,888
tensorflow/tensorflow,901e654521939d069f15e1bd4caf0802194624b2,Greg Olechwierowicz,2025-07-10T11:17:40Z,[XLA:GPU] Bubble up status handling in unified latency estimator.  PiperOrigin-RevId: 781470886,156,131,287
tensorflow/tensorflow,7cb0699ad086df9d7c24218203a08491a43e0554,Henning Becker,2025-07-10T10:05:43Z,Fix unoptimized HLO Snapshots  A recent refactoring has changed the behaviour of the unoptimized HLO Snapshots in such a way that they were dumping optimized HLO. This change rectifies that and adds a test that protects that behaviour.  PiperOrigin-RevId: 781451141,109,19,128
tensorflow/tensorflow,9c46514516ff47e6307361ff761fa16688e63772,Allan Renucci,2025-07-10T09:49:16Z,Manually migrate deprecated references to `strings::StrCat` and `strings::StrAppend`.  `strings::StrCat` and `strings::StrAppend` should eventually forward to `absl::StrCat` and `absl::StrAppend`. Some references need to be rewritten as `absl::StrCat(absl::LegacyPrecision(...))` to avoid loss of precision.  This is a no-op change.  PiperOrigin-RevId: 781446485,45,21,66
tensorflow/tensorflow,78f4b7dc3130cd608f990f1235dcb3d68ec5fccd,Will Froom,2025-07-10T09:22:20Z,[XLA:CPU] Use C style names when required in new fusions.  PiperOrigin-RevId: 781439093,26,7,33
tensorflow/tensorflow,dd6a4188363ad2aa7add21e690da81a8979b4128,A. Unique TensorFlower,2025-07-10T09:14:30Z,LOG(INFO) -> VLOG(4) for layout_canonicalization_callback.  PiperOrigin-RevId: 781436550,1,1,2
tensorflow/tensorflow,2dbb92458abb5d96ef596acb37ffb6f49e3b5deb,A. Unique TensorFlower,2025-07-10T09:03:04Z,compat: Update forward compatibility horizon to 2025-07-10  PiperOrigin-RevId: 781432355,1,1,2
tensorflow/tensorflow,169bbeedb2c5440666ea2a3a71c36c71798a39b0,A. Unique TensorFlower,2025-07-10T09:03:02Z,Update GraphDef version to 2284.  PiperOrigin-RevId: 781432336,1,1,2
tensorflow/tensorflow,fa4e206d73bd51a26af3d547b2dd6bbcef8fecec,Adrian Kuegel,2025-07-10T08:57:59Z,"Pass the correct backend-specific AliasInfo to HloMemoryScheduler  The AliasInfo is needed to compute Peak Memory. Theoretically there could be users of HloMemorySchedule which don't want to compute peak memory, but it seems not worth it making AliasInfo optional depending on whether peak memory should be computed. Adapt direct and indirect users of HloMemoryScheduler accordingly.  PiperOrigin-RevId: 781430019",391,225,616
tensorflow/tensorflow,fccd619d7646c5c3c83d0a10da80b40883325a14,A. Unique TensorFlower,2025-07-10T08:57:06Z,Automated Code Change  PiperOrigin-RevId: 781429676,11,0,11
tensorflow/tensorflow,b78a476d4babd3b92b03b695d6ef11f6efeb12b6,Will Froom,2025-07-10T08:51:27Z,[XLA:CPU] Add pass to peel loop for workgroups that cross the constraints.  PiperOrigin-RevId: 781427727,318,0,318
tensorflow/tensorflow,e5982331c429fce7c9c4389f2d15eee5ff3e9791,Terry Heo,2025-07-10T06:02:38Z,Reverts a11dafed1c38656e665f258fb55da77e1c04eefb  PiperOrigin-RevId: 781377322,140,196,336
tensorflow/tensorflow,2fa59af8b6000d7520dbf747e5e96d8e1083de1e,A. Unique TensorFlower,2025-07-10T05:49:10Z,Enabling XLA early exit after layout assignment  PiperOrigin-RevId: 781373968,5,1,6
tensorflow/tensorflow,2e245e0e6b2fc5f40268d2af8dc985b12b8fa213,A. Unique TensorFlower,2025-07-10T05:38:12Z,Automated Code Change  PiperOrigin-RevId: 781370948,1,0,1
tensorflow/tensorflow,230150b8c479c6efba4aae504a33ba53a7bccccc,A. Unique TensorFlower,2025-07-10T05:27:16Z,Automated Code Change  PiperOrigin-RevId: 781367679,4,0,4
tensorflow/tensorflow,affbba93457588e5623f92fa2ecd6d21a941dead,A. Unique TensorFlower,2025-07-10T05:14:39Z,Automated Code Change  PiperOrigin-RevId: 781364124,1,1,2
tensorflow/tensorflow,00a69490cd18804969ce913dfa594785ab5fc740,Shahriar Rouf,2025-07-10T05:13:10Z,"Optimize `xla::HloInstruction::OperandIndices`.  - Don't call `operand_count()` on each iteration. `InlinedVector::size` is more expensive than `vector::size`. It needs a branch first to understand where the storage is. - Use `InlinedVector::data` and pointer arithmetic instead of `InlinedVector::operator[]` which, again similar to `InlinedVector::size`, needs a branch on each call. - Motivation for the `s/int64_t/size_t/` change: https://godbolt.org/z/oW59K668a.  PiperOrigin-RevId: 781363727",4,2,6
tensorflow/tensorflow,34d0d4e3410141beb2430f644f822cf5eb2c4777,A. Unique TensorFlower,2025-07-10T04:10:30Z,Do not start XNNPACK fusions with widening converts.  It's better to fuse widening converts into their consumer.  PiperOrigin-RevId: 781346697,40,0,40
tensorflow/tensorflow,4b5efb7afe49180e14a90e1b39e063290354b2aa,Eugene Zhulenev,2025-07-10T03:31:13Z,[xla:codegen] Add Intrinsic::GetOrInsertDeclaration  PiperOrigin-RevId: 781335122,59,26,85
tensorflow/tensorflow,e59873f52a4f9b08b45e334c11dcc610bfd30fd2,A. Unique TensorFlower,2025-07-10T01:43:20Z,Expose Auto Sharding to StableHLO.  PiperOrigin-RevId: 781300386,450,10,460
tensorflow/tensorflow,d469700dbe8c06c1eacaa8cc66b4e903eb8a71a6,A. Unique TensorFlower,2025-07-10T01:12:43Z,"[XLA] Add documentation for table lookup pattern.  Adds comments to explain what a ""table lookup"" is and how it is used in the collective optimization passes.  PiperOrigin-RevId: 781291908",29,1,30
tensorflow/tensorflow,eea069e8454160f3a8a793fe77446fdb12f72f41,Vlad Sytchenko,2025-07-10T01:12:27Z,Allow single core embeddings  PiperOrigin-RevId: 781291822,7,4,11
tensorflow/tensorflow,1773d87b768685a761bfcb3f2a4d66caeff7bdb2,Ziyin Huang,2025-07-10T00:22:46Z,"Use the dst device to do the d2d transfer. Instead of waiting for the src buffer definition event, we need to wait for the ready event.  PiperOrigin-RevId: 781275073",3,3,6
tensorflow/tensorflow,7bc466b24424d96907d7797044f035b1ee8198ad,Eugene Zhulenev,2025-07-10T00:15:37Z,[xla:codegen] Define XLA Intrinsics: initial commit with documentations and basic functionality  PiperOrigin-RevId: 781272944,228,19,247
tensorflow/tensorflow,a11dafed1c38656e665f258fb55da77e1c04eefb,Terry Heo,2025-07-09T23:26:58Z,"lite: Propagate an error during OpInit()  Delegate kernels may fail during TfLiteRegistration.init(). In this case, Delegate kernel returns TfLiteKernelInitFailed() to notify. If it happens, user's call to InterpreterBuilder::operator() or Interpreter::ModifyGraphWithDelegate() will fail.  Updated SimpleDelegate to use TfLiteKernelInitFailed() instead of nullptr.  Also refactored delegate_test_util to simpler to use.  PiperOrigin-RevId: 781256289",196,140,336
tensorflow/tensorflow,c51798e3c791dfd9187dc0f0b625633fa824f783,Eugene Zhulenev,2025-07-09T22:38:53Z,[xla:cpu] Port elemental ir emitter to use XLA intrinsic for f32 to bf16 truncation  PiperOrigin-RevId: 781238590,253,28,281
tensorflow/tensorflow,c176208f0754433f08552e5082a2e896e2efa62a,Allan Renucci,2025-07-09T22:30:34Z,Fix several LINT errors.  PiperOrigin-RevId: 781235765,43,41,84
tensorflow/tensorflow,f017bc88147dd1ed5e255740bab77bbc5755f005,Jian Cai,2025-07-09T22:28:20Z,[XOA][Numerics][HLO Value Tracking] Add a TODO  PiperOrigin-RevId: 781234948,4,2,6
tensorflow/tensorflow,6686efd9667758d7e3dc0a3a337b4e842129dd76,A. Unique TensorFlower,2025-07-09T22:12:05Z,Solve BUILD deps conflict for linear_solver  PiperOrigin-RevId: 781229194,11,0,11
tensorflow/tensorflow,2a54fd2028b7115beca2d6b955cd972f82000523,Marcello Maggioni,2025-07-09T21:35:41Z,"[XLA] Add support in collective pipeliner to pipeline forward instructions that are ""sink""  Sink means instructions that have some data as input and only output a token, like  data [8,128,128] = data() cc token[] = custom-call(data)  PiperOrigin-RevId: 781214933",347,104,451
tensorflow/tensorflow,9c9dea42219bd88e9f3fe8147ae2ff6ee83bc09a,A. Unique TensorFlower,2025-07-09T21:34:36Z,Implement LoadedExecutable::GetCompiledMemoryStats() and SizeOfGeneratedCodeInBytes() for proxy.  PiperOrigin-RevId: 781214535,61,2,63
tensorflow/tensorflow,c8336ea133d6d3988223d4419d494de6909cc46f,Kevin Gleason,2025-07-09T21:19:27Z,[stablehlo] Support bounded dimensions in dot op type inference  PiperOrigin-RevId: 781208712,90,0,90
tensorflow/tensorflow,4b4379d3bb4cfb8ca5c759e7d9fa26d96944a9bd,Daniel Chen,2025-07-09T21:06:50Z,[ #HLODiff ] Synchronize scroll for textbox pair  PiperOrigin-RevId: 781203248,31,7,38
tensorflow/tensorflow,b955de4b85700e218ec70b93c26543c9c124dab7,Parker Schuh,2025-07-09T20:42:48Z,Expose GetBufferWithHold as a public API.  PiperOrigin-RevId: 781192893,2,2,4
tensorflow/tensorflow,825df80373fba0bd45672ffdbcf5498c39831aca,Ezekiel Calubaquib,2025-07-09T20:02:59Z,Fix converter copybara removal of learning for oss side  PiperOrigin-RevId: 781176593,3,4,7
tensorflow/tensorflow,2acb69125bd2261ea3aa81e836fd2f486d2fcf35,Will Froom,2025-07-09T19:45:13Z,[XLA:CPU] Add pass to add loop unroll flags to nested scf.ForOps  PiperOrigin-RevId: 781170081,241,3,244
tensorflow/tensorflow,6fb8e909a9fbc9f773d316d29df54c2453ef739a,Jian Cai,2025-07-09T19:26:26Z,[XLA][Numerics][HLO Value Tracking] Fix printing format of the recovery table  PiperOrigin-RevId: 781162976,11,9,20
tensorflow/tensorflow,b1da58a55a9534e31d16aab64f0abbdd8509ad68,A. Unique TensorFlower,2025-07-09T19:06:40Z,No public description  PiperOrigin-RevId: 781155260,8,6,14
tensorflow/tensorflow,b8854bc9cdebaccc0e2fa22666e2d2d729b80ba3,Parker Schuh,2025-07-09T18:48:43Z,Add Delete() to CommonPjRtBufferImpl implemented via AbstractTrackedDeviceBuffer::Delete().  PiperOrigin-RevId: 781147116,44,20,64
tensorflow/tensorflow,5d3b3b7e78b43f460214f3e238e17a29581354f6,Junwhan Ahn,2025-07-09T18:28:20Z,Remove the deprecated version of `Array::DisassembleIntoSingleDeviceArrays`  PiperOrigin-RevId: 781138001,0,11,11
tensorflow/tensorflow,68c08f4f477d9067ff8c01c0f3458132505ce353,Buddh Prakash,2025-07-09T18:16:28Z,Don't use position-based matching for entry computations.  PiperOrigin-RevId: 781133140,6,3,9
tensorflow/tensorflow,b97375818390d7ea4b0a81ee8b048f796076e06d,Thomas Joerg,2025-07-09T17:48:16Z,[XLA:GPU] Do not fuse sibling transpose fusions with different memory read patterns.  PiperOrigin-RevId: 781120814,43,0,43
tensorflow/tensorflow,4b3df8be6ab7433ff7a9d60408e978769181052e,Dirk Hornung,2025-07-09T17:36:50Z,"Add AutotunerPass.  The autotuner can be enabled by the --xla_gpu_use_autotuner_pass flag. The autotuner pass uses the new autotuning backends to autotune hlo instructions. The autotuner is currently placed next to the GemmFusionAutotuner, but will be moved close to Codegen after validating its functionality and performance.  PiperOrigin-RevId: 781116016",364,29,393
tensorflow/tensorflow,4870a34f6b5be3eaacb22d674d2e4bbc0396d73b,Jian Cai,2025-07-09T17:20:26Z,[XLA][Numerics][HLO Value Tracking] Copy original values when creating a clone with same shape  PiperOrigin-RevId: 781108897,27,8,35
tensorflow/tensorflow,5fc10157f29f897d7975baa5985f5a506b656e16,Karlo Basioli,2025-07-09T16:51:07Z,[tfcompile] Use xla::cpu::Align instead of hardcoded constant.  PiperOrigin-RevId: 781096209,5,10,15
tensorflow/tensorflow,037f5a46c5acae6d271dbc20ccb0bc12f899e7ff,A. Unique TensorFlower,2025-07-09T16:44:55Z,"Move xla_workspace4() and xla_workspace3() calls above Python init.  python_init_repositories() loads its own version of bazel_skylib, which causes the http_archive() dep in xla_workspace3() to be ignored.  This is how it's already done in TensorFlow.  PiperOrigin-RevId: 781094000",8,8,16
tensorflow/tensorflow,b55fe5ec20006e340c0fcb14e9dbd0682c9b72b7,Allan Renucci,2025-07-09T16:29:44Z,Inline unique usage of `tsl::internal::LogString`.  PiperOrigin-RevId: 781088440,8,21,29
tensorflow/tensorflow,bf866a300c8d3c1d895529cd986dddbd178f833c,Will Froom,2025-07-09T16:03:49Z,[XLA:CPU][XLA:GPU] Add fast min/max rewrite pattern.  PiperOrigin-RevId: 781078198,118,8,126
tensorflow/tensorflow,fc95419684a3bbfda985f00d4633b2db308a8a85,Karlo Basioli,2025-07-09T16:01:43Z,[XLA:CPU] Make cpu alignment header public in OSS.  PiperOrigin-RevId: 781077271,1,0,1
tensorflow/tensorflow,860e226dad760acc6f0175d2ef8e18df67f82457,Karlo Basioli,2025-07-09T15:49:13Z,[XLA][host offllading] Open source host offloading hlo utils  PiperOrigin-RevId: 781072721,610,0,610
tensorflow/tensorflow,37fdda33ae7ae1fd2c8cfb731f707f8806c06cde,Alexander Lyashuk,2025-07-09T15:33:20Z,"[XLA:GPU] [NFC] Move Algebraic Simplifier configs to one place  It was hard to track what simplification runs when, and when you want to enable and disable some transformation, it's hard to find all places you have to touch.  The change is intended to be a NOOP change. The attempt to actually make configs more unified will come in a later change.  PiperOrigin-RevId: 781066663",104,100,204
tensorflow/tensorflow,9b4ea517477ade201e38c83b61f1a274d1ab82c5,Michael Kuperstein,2025-07-09T14:59:40Z,"[XLA] Update comment.  `IdenticalIgnoringChannelIdValues` passes `ignore_commutative_operand_order=true`, like `IdenticalIgnoringCommutativeOperandOrder` and unlike `Identical`.  PiperOrigin-RevId: 781053824",3,2,5
tensorflow/tensorflow,fe988098276f38ef187742fbef5e3fc9478dc8b7,Mohammed Anany,2025-07-09T14:52:04Z,"[XLA:GPU/TMA] Extend current autotuner to add TMA optionality to Triton configs.  We also extend block-level and triton-gemm configurations to include a flag for TMA. The flag will be used to enable/disable TMA for all arguments of the kernel, where physically possible.  PiperOrigin-RevId: 781050886",295,87,382
tensorflow/tensorflow,be170e760b59697bd7aa63d78fad26fec90aca5f,Allan Renucci,2025-07-09T14:35:03Z,[XLA:GPU] Use an enum to represent the GPU topology type.  PiperOrigin-RevId: 781045346,60,56,116
tensorflow/tensorflow,8352e38109abdc2198247e60bcd3480f449a9b45,Will Froom,2025-07-09T13:55:35Z,[XLA:CPU] Don't enable verifier by default.  PiperOrigin-RevId: 781031240,32,9,41
tensorflow/tensorflow,e0f843603918a21f1a068ec18552b537dd4a7c86,Allan Renucci,2025-07-09T13:35:55Z,Remove `third_party/absl/flags/flag.h` header export in TSL logging library.  And fix transitive dependencies.  PiperOrigin-RevId: 781024653,7,3,10
tensorflow/tensorflow,94e0f604809b8ddaa69a3fe34ed510d2c1807fbc,Adrian Kuegel,2025-07-09T13:20:30Z,"[XLA:GPU] Handle nested tuples in FusionCanShareBufferHint.  With DynamicSliceFusion enabled, we can have cases where a fusion has a nested tuple. So going one step up from the root may not be enough to get to the real output. Migrate AliasInfo related tests to their own test target.  PiperOrigin-RevId: 781019728",897,835,1732
tensorflow/tensorflow,b05583861f895a3bdeb7c057706d00394fb06c3d,A. Unique TensorFlower,2025-07-09T12:47:57Z,Go: Update generated wrapper functions for TensorFlow ops.  PiperOrigin-RevId: 781009009,8,0,8
tensorflow/tensorflow,cc792635229ab2ba91d8a420fde0a86f58042c53,A. Unique TensorFlower,2025-07-09T12:27:09Z,Reverts 24c2972bdcee3d159f4c72d57ff1c7be8a100e54  PiperOrigin-RevId: 781003055,8,240,248
tensorflow/tensorflow,6c2d92fac3cb229f2ce6b10597b1910f6ef548e2,A. Unique TensorFlower,2025-07-09T12:19:47Z,Update ops-related pbtxt files.  PiperOrigin-RevId: 781000132,103,0,103
tensorflow/tensorflow,73e2e89cb12079034158c3ed045316a5f4e47d73,Sergey Kozub,2025-07-09T12:17:19Z,"PR #28184: Extend `WhileLoopAllReduceCodeMotion` pass with a new pattern (DUS)  Imported from GitHub PR https://github.com/openxla/xla/pull/28184  We're seeing a pattern in Llama3 model (fp8) where all-reduce happens inside the loop, but the results are only used outside of the loop. When there are many participating devices, this could result in a slowdown.  The pass now also matches all-reduces that are scattered into the loop output using ""dynamic-update-slice"" op with the loop induction variable as the index parameter. Copybara import of the project:  -- 6075de4340b7273c8d63641aeca88fb5ffd7f4a7 by Sergey Kozub <skozub@nvidia.com>:  Extend `WhileLoopAllReduceCodeMotion` pass with a new pattern (DUS)  Merging this change closes #28184  PiperOrigin-RevId: 780999371",1016,57,1073
tensorflow/tensorflow,c465a2d6af262f41a7c12c5eda8fc2fdc92284c4,Karlo Basioli,2025-07-09T11:25:13Z,[tfcompile] Improve initialization time for models compiled with the thunk runtime.  Optimizations made - don't copy constants for initialization - don't allocate memory for constants (since we're not copying into it) - don't keep a copy of the function symbols hash map  PiperOrigin-RevId: 780984664,36,21,57
tensorflow/tensorflow,54295f102bed36ab35d9355a84ed505daf1df160,Goran Flegar,2025-07-09T11:21:15Z,Reduce warning level for incompatible default tile set to info  PiperOrigin-RevId: 780983462,4,4,8
tensorflow/tensorflow,0076e3e2a7183e8d39854bdbfad582eb0438ba8a,Zixuan Jiang,2025-07-09T11:01:33Z,"Add `use_shardy_partitioner` in `tf.tpu.XlaOptions`, `TPUReplicateMetadata`. The default value is false.  PiperOrigin-RevId: 780975971",41,11,52
tensorflow/tensorflow,0cd86861692766aca41ecbff05bb99e4669a0a85,Alexander Belyaev,2025-07-09T11:01:04Z,[XLA:GPU] Use TilingSpace to lookup RTVars for dynamic slice tiling.  PiperOrigin-RevId: 780975832,142,140,282
tensorflow/tensorflow,3b322e50ed7cecf8b8d8c44513d9d442ce20238b,A. Unique TensorFlower,2025-07-09T10:08:18Z,Automated Code Change  PiperOrigin-RevId: 780959099,13,0,13
tensorflow/tensorflow,6a3027dbebbe7f13eb7911f679906ca7a454bf24,Allan Renucci,2025-07-09T09:58:55Z,Remove unused `tensorflow` namespace aliases.  We also update the unique usage of `UpdateLogVerbosityIfDefined` to not use the  `tensorflow` qualifier.  PiperOrigin-RevId: 780955815,9,20,29
tensorflow/tensorflow,d4766037b7577dc4d8966bc41b68c03418de109a,A. Unique TensorFlower,2025-07-09T09:03:56Z,Automated Code Change  PiperOrigin-RevId: 780936133,22,12,34
tensorflow/tensorflow,2c217bcdfa97f7d817367cd79ae7def0150aaea9,A. Unique TensorFlower,2025-07-09T09:03:07Z,compat: Update forward compatibility horizon to 2025-07-09  PiperOrigin-RevId: 780935764,1,1,2
tensorflow/tensorflow,5442b28a0236201ed8fd5a71bb17675e433f64c8,A. Unique TensorFlower,2025-07-09T09:02:55Z,Update GraphDef version to 2283.  PiperOrigin-RevId: 780935650,1,1,2
tensorflow/tensorflow,477bba02b5e09451eb4177184673f376ee57c25e,Adrian Kuegel,2025-07-09T08:50:38Z,Migrate remaining users of CanShareBuffer hook to AliasInfo (NFC)  Delete CanShareBuffer related code.  PiperOrigin-RevId: 780931035,49,109,158
tensorflow/tensorflow,52e72defab7af4fffd889f99572a95cdbb783718,A. Unique TensorFlower,2025-07-09T08:45:11Z,Update use of deprecated XNNPACK APIs  PiperOrigin-RevId: 780928593,59,88,147
tensorflow/tensorflow,452a455fe594212c2de1e768d247bba64f4a5fdc,A. Unique TensorFlower,2025-07-09T07:50:55Z,Automated Code Change  PiperOrigin-RevId: 780909178,1,2,3
tensorflow/tensorflow,51ee1bee47e995f26593a13d9b249393c606353d,Haibo Huang,2025-07-09T07:19:27Z,Set c api versions in tfrt_gpu_client.cc  PiperOrigin-RevId: 780898958,2,0,2
tensorflow/tensorflow,bb2dcbf14588edd775369f0591bb59e05712b47d,A. Unique TensorFlower,2025-07-09T07:17:25Z,Automated Code Change  PiperOrigin-RevId: 780898250,8,0,8
tensorflow/tensorflow,0a8cce2896211a420bc613ba6bcea113efa15703,Adrian Kuegel,2025-07-09T07:08:50Z,Migrate from CanShareBuffer hook to AliasInfo.  PiperOrigin-RevId: 780895093,40,28,68
tensorflow/tensorflow,38e32269d61709849c7dbfc7e04fed16b00c0be9,TensorFlower Gardener,2025-07-09T06:53:36Z,Merge pull request #96408 from tensorflow:dependabot/pip/ci/official/requirements_updater/numpy1_requirements/setuptools-78.1.1  PiperOrigin-RevId: 780886988,13,13,26
tensorflow/tensorflow,cc78bbe188689b130841cc23fd797a7c2e5cc0df,TensorFlower Gardener,2025-07-09T06:05:51Z,Merge pull request #96407 from tensorflow:dependabot/pip/ci/official/requirements_updater/numpy1_requirements/requests-2.32.4  PiperOrigin-RevId: 780873054,12,12,24
tensorflow/tensorflow,1a12437c47a48ca35a54d09436f1aca6e5c75baf,Vlad Sytchenko,2025-07-09T05:23:59Z,[XLA] Make dumping blazingly fast  Scanning the file system during each dump to check how many module we've dumped can slow things down drastically. Reuse the timestamp map to keep track of this.  PiperOrigin-RevId: 780864260,42,53,95
tensorflow/tensorflow,29008ee022280c2636e66cb59bb8fa1dbca5babf,Buddh Prakash,2025-07-09T04:10:42Z,[HLO Diff] Cache right node bfs traversals to speed up DiceSimiliarity calculations.  PiperOrigin-RevId: 780843435,52,28,80
tensorflow/tensorflow,423a379a6c70ddb4e790337da1d991350a0b7178,A. Unique TensorFlower,2025-07-09T04:01:51Z,Automated Code Change  PiperOrigin-RevId: 780840832,0,1,1
tensorflow/tensorflow,2b9f86e4985ca1f5d111243b0375b0df0627f8e9,Buddh Prakash,2025-07-09T01:14:12Z,Refactor BiDirectionalMap to fully hide internals and expose a symmetric API.  PiperOrigin-RevId: 780793848,262,118,380
tensorflow/tensorflow,bc74ce3a9f51a306eb6d4828e3365c47b482ba6e,Subhankar Shah,2025-07-09T00:30:03Z,[XLA:MSA] Use max_size_in_bytes instead of available_heap_size() for memory space coloring. It is incorrect to use available_heap_size() because it means remaining available heap size and want to use total heap size available for MSA which is given by max_size_in_bytes.  PiperOrigin-RevId: 780779230,3,3,6
tensorflow/tensorflow,5a43478b7a44481ed57242a34f9ed289307d257d,A. Unique TensorFlower,2025-07-09T00:26:50Z,#HLODiff Add lcs parent similarity to MatchInstructionsWithMultipleCandidates  PiperOrigin-RevId: 780778389,6,3,9
tensorflow/tensorflow,ea88fac2106e5bb9a5f2aede175f2e93f0d660fc,David Dunleavy,2025-07-09T00:17:19Z,Delete `xla_test_library` and associated arguments used by other macros  PiperOrigin-RevId: 780775467,0,71,71
tensorflow/tensorflow,87380e5531f10558e5d807aa399a30d2d0360574,A. Unique TensorFlower,2025-07-09T00:13:10Z,Automated Code Change  PiperOrigin-RevId: 780773917,4,3,7
tensorflow/tensorflow,10c58d6e31c25db9183d7cd529ff3a24ac76eb71,A. Unique TensorFlower,2025-07-08T23:43:49Z,"[TFLite] Fix incorrect `FuseBinaryOpWithTransposeConvNoneBias` optimization  This commit fixes folding of `F16` `Constant` from a `BinaryOp` (Add or Sub) into the bias of `TransposeConv`, i.e., from `TransposeConv(NoneBias)->Add/Sub(Constant)` to `TransposeConv(Bias)`, where the `Constant` is converted to the `Bias` in `TransposeConv`. During conversion, `GetBiasMultiplier` function returns a `Multiplier` of `1.0` or `-1.0` depending on `BinaryOp` type (Add or Sub), i.e., `Bias = Constant * Multiplier`. Therefore, it is required that the `Multiplier` has the same datatype as the `Constant`.  Before the fix, this multiplier's datatype is `F32` regardless of the datatype of the `Constant`. This causes error when the `Constant` is `F16`, and the `MulOp` which multiplies the two values returns all-zero values, resulting in an all-zero `Bias`.  After the fix, the `Multiplier` datatype is determined by the `Constant` datatype and the converted `Bias` values are correct for `F16` case.  PiperOrigin-RevId: 780764250",44,6,50
tensorflow/tensorflow,62a86022f512439a9a8c2bd3ea8da6997fbcb296,Toli Yevtushenko,2025-07-08T23:22:50Z,Eliminate circular dependency between device assignment and Computation Placement. Use Device Assignment for looking up logical and global ids.  PiperOrigin-RevId: 780757147,83,76,159
tensorflow/tensorflow,a5711b23b37ba4ad54fed87e478aa14fce2d7c01,Victor Stone,2025-07-08T23:11:25Z,Support Conditional in HostOffloader.  PiperOrigin-RevId: 780753038,117,11,128
tensorflow/tensorflow,71b0309af73999a5e792b4cdbf6db1be305c74eb,A. Unique TensorFlower,2025-07-08T22:41:06Z,Make stateless methods static in XnnGraphFusion. NFC.  PiperOrigin-RevId: 780741805,4,4,8
tensorflow/tensorflow,2d67f1016a0fb9dce279f1e12a9d2d8c971554f1,T.J. Alumbaugh,2025-07-08T21:59:58Z,"Add (filename, offset, length) for disabled MMAPAllocation ctors  PiperOrigin-RevId: 780727101",4,0,4
tensorflow/tensorflow,0ec77932eae8e26069e207d6ea5f55a7dcd124f3,Mason Chang,2025-07-08T21:55:09Z,Unnest GetShardingFromNodeDef for readability  PiperOrigin-RevId: 780725631,35,25,60
tensorflow/tensorflow,3177c42be55133317d4684553e5b2eb9e12db9ed,David Dunleavy,2025-07-08T21:39:41Z,"Remove all uses of `xla_test_library`  Followup will delete definitions, delete `xla_test_libraries` argument used by other macros.  PiperOrigin-RevId: 780719981",7,6,13
tensorflow/tensorflow,45df82e9c655ba177a0459e0c5077c082cbf8fa0,Buddh Prakash,2025-07-08T21:36:32Z,Simplify HloComputationGraphMatcher by re-using leaf matcher for constant and params  PiperOrigin-RevId: 780718771,39,116,155
tensorflow/tensorflow,589fde13b32d0ef1648b341f5ec5f06229ccbd2b,Tommy Chiang,2025-07-08T21:15:25Z,"Return kTfLiteDelegateError if delegate_kernel is null  If the delegate kernel failed to Init, we will return a nullptr. However, we didn't check when doing Prepare, which will cause a null pointer dereference crash.  This CL avoids this by properly check and return error before accessing a potentially null pointer.  PiperOrigin-RevId: 780710630",6,1,7
tensorflow/tensorflow,b263c92206aa186d518c22d602d1c8a594bc9ba0,Alexander Belyaev,2025-07-08T21:07:59Z,[XLA:GPU] Add TilingSpace.  PiperOrigin-RevId: 780707413,514,0,514
tensorflow/tensorflow,324ccb558f0dfc8d06c17d1db2faf22b7d476faa,Ziyin Huang,2025-07-08T21:01:57Z,add supports_cross_host_transfers attribute to the new pjrt gpu client.  PiperOrigin-RevId: 780704596,2,1,3
tensorflow/tensorflow,26d9e65186ab04079a1219357bbadd76eb1142cc,David Pizzuto,2025-07-08T20:22:30Z,"strict_cc_test: Only set --gtest_fail_if_no_test_selected on CI.  Local development is reasonably likely to want to use --gtest_filter to run only a subset of test cases, and in the case of sharded tests this flag results in spurious failures.  PiperOrigin-RevId: 780689663",8,3,11
tensorflow/tensorflow,e1f452813b2885a8db43f966c7f58dcae09ff12b,Allan Renucci,2025-07-08T19:50:16Z,Upgrade Abseil to [LTS 20250127.1](https://github.com/abseil/abseil-cpp/releases/tag/20250127.1).  Not upgrading to [20250512.1](https://github.com/abseil/abseil-cpp/releases/tag/20250512.1) since it breaks Protobuf. These two libraries probably need to be upgraded together.  PiperOrigin-RevId: 780677104,335,340,675
tensorflow/tensorflow,ad00222ec2ad3ebd41a4526b861d99fa07e06658,Buddh Prakash,2025-07-08T19:27:23Z,[HLO Diff] Precompute HLO values dependencies for each instruction in graph.  The instruction dependencies can be useful not just for bottom-up matcher but other matchers and similarity measures as well.  PiperOrigin-RevId: 780668827,122,59,181
tensorflow/tensorflow,2b907dd4cb9acc55b019eefaad952ac81ed7b0ad,David Dunleavy,2025-07-08T18:43:02Z,Move `tensorflow/third_party/shardy` to `xla/third_party/shardy`  PiperOrigin-RevId: 780652350,2,474,476
tensorflow/tensorflow,ac0bfda0c7340d92c1d36d0337e2e1181254bf5d,A. Unique TensorFlower,2025-07-08T18:29:59Z,Implement `xnn_scheduler` using `Eigen::ThreadPoolInterface` to redirect XNNPACK parallelism to the XLA thread pool.  Other changes in this CL: - `DebugOptions::XNN_GRAPH_FUSION_MODE_GREEDY_SLINKY` now indicates that slinky should be used (and controls which kind of thread pool gets created).  PiperOrigin-RevId: 780647272,149,29,178
tensorflow/tensorflow,09ee896064b5412cb62e143eadb5920ba7afbfaa,David Dunleavy,2025-07-08T18:27:51Z,Use `std::min` instead of `MIN` in `bipartite_matching.cc`  `MIN` causes problems when used with gcc.  PiperOrigin-RevId: 780646584,3,2,5
tensorflow/tensorflow,196d590e258ed8da586cbc9bc90f51e51f28be23,Emily Fertig,2025-07-08T18:23:47Z,Reverts e2e1ae8fd027c9bdd6e75181e0d5aaaa6a7a12c6  PiperOrigin-RevId: 780645251,13,323,336
tensorflow/tensorflow,6ccfb6e5e3bd52176c57999141fa4114717f606b,Sandeep Dasgupta,2025-07-08T18:16:49Z,[Phase Compilation] Part-3: Augment extension with buffer deletion callback.  PiperOrigin-RevId: 780642468,173,9,182
tensorflow/tensorflow,dcb11994fcfa4a2c893b6822354c1380f3e572f3,Karlo Basioli,2025-07-08T18:03:11Z,[XLA][host offloading] Open source host offloading layout analysis.  PiperOrigin-RevId: 780635346,376,0,376
tensorflow/tensorflow,c3f2e1a9c66e7c2a180ec75bf69da787fc23baf8,jparkerh,2025-07-08T17:15:40Z,"Add no-arguments compiler client  Add a version of the GetCApiCompiler that takes no arguments - this checks to make sure there's exactly one platform registered in pjrt, and then uses that platform to generate the compiler.  PiperOrigin-RevId: 780614807",37,3,40
tensorflow/tensorflow,f670d4731e317c573349a8c3177b44b85b06a575,A. Unique TensorFlower,2025-07-08T17:08:22Z,#sdy Move `AddAxisOrMergeInserter` to Shardy OSS utils.  PiperOrigin-RevId: 780611537,1,0,1
tensorflow/tensorflow,fa15ae7391589290d85e8855e974e930d68617c9,Will Froom,2025-07-08T16:52:24Z,[XLA:CPU][XLA:GPU] Use nsw rather than nuw  PiperOrigin-RevId: 780603812,10,10,20
tensorflow/tensorflow,a350978698a1d89d4f0e2a6d9d5ea1cea4a3f859,Will Froom,2025-07-08T16:18:18Z,[XLA:CPU] Add tile size to WorkDimensions.  PiperOrigin-RevId: 780589961,249,53,302
tensorflow/tensorflow,3d88db074d612785687a8f4d972f90330e115693,Ilya Tikhonovskiy,2025-07-08T15:39:28Z,[XLA:GPU] Do not drop low occupancy configs if the search space is small  Low occupancy configs happen when the output size is small. If the number of configs is small it still makes sense to keep these configs. The win in the compile time will be negligible.  PiperOrigin-RevId: 780577138,14,5,19
tensorflow/tensorflow,221479959bf4d0f5a20c23817e2f10fd0c94e113,Oleg Shyshkov,2025-07-08T13:49:10Z,[XLA:GPU] Simplify interfaces in CoalescingAnalysis.  A few NFC simplifications: * We don't need to pass `HloFusionAdaptor`. It's already available in `HloFusionAnalysis`. * `ComputeCoalescingForAllOperands` can be a stand-alone function outside of `CoalescingAnalysis`. * No need to pass `KernelFusionInterface`. It's fairly cheap to reconstruct from the analysis  PiperOrigin-RevId: 780542787,96,85,181
tensorflow/tensorflow,a1203d901edfc3249a1d8a873fbe1bdf169ff3d7,A. Unique TensorFlower,2025-07-08T13:39:38Z,Make RequestGpuInfo work for OpenGL < 3.1 as well  Some enums like the compute shader enums fail to query for OpenGL < 3.1.  PiperOrigin-RevId: 780540412,15,13,28
tensorflow/tensorflow,8d62240cb9e98bad69c9038247ca9631a92bfcb7,Karlo Basioli,2025-07-08T13:18:44Z,[XLA][host offloading] Open source host offloading allocator interface.  PiperOrigin-RevId: 780535586,95,0,95
tensorflow/tensorflow,807c63b5a4e6ba2e6aad5e260423723425c23011,Allan Renucci,2025-07-08T12:58:07Z,Remove obsolete rewrite from `TFLogEntry::text_message_with_prefix` to `TFLogEntry::ToString`  PiperOrigin-RevId: 780528768,1,1,2
tensorflow/tensorflow,b2058d593d655d6f94b343c584733404372acfa6,Oleg Shyshkov,2025-07-08T12:53:53Z,"[XLA:GPU] Reset heroes to roots if we device to use loop emitter.  Even if there are non-trivial roots in the fusion, there are cases we want to fall back to the loop emitter. Loop emitter expects that heroes are always roots of the fusion.  PiperOrigin-RevId: 780527758",277,137,414
tensorflow/tensorflow,fa34a829155ba2b87265128f2c5cc8f0a588ba82,Adrian Kuegel,2025-07-08T12:03:02Z,"[HLO_OPT]: Move CopyInsertion pass registration to hardware dependent passes.  This is needed because it requires AliasInfo, which is backend specific. Also let GpuAliasInfo take a se::DeviceDescription instead of a pointer, as the life time of the DeviceDescription in the opt tool is not sufficient, it would be deleted before the pass is run.  PiperOrigin-RevId: 780515794",35,19,54
tensorflow/tensorflow,2e1457f3e673c22da757b6e9b6cccc6eb90aeaeb,Karlo Basioli,2025-07-08T11:21:49Z,[XLA][host offloading] Open source HostOffloadingBuffer.  PiperOrigin-RevId: 780506047,103,0,103
tensorflow/tensorflow,075bc820f4c020ff8d7555a12e7bdde3e1fe9de6,Adrian Kuegel,2025-07-08T10:54:27Z,"Remove redundant check in CopyRemover (NFC).  We are comparing shapes for equality with the default equality operator. That includes comparing layouts, which in turn makes sure that memory spaces are the same. So it is not necessary to check separately whether we have a device to host or host to device copy, those would have different memory spaces.  PiperOrigin-RevId: 780498246",2,21,23
tensorflow/tensorflow,273bbb1f5362d34234c9f33d16c540006bdee97e,Ilya Tikhonovskiy,2025-07-08T10:44:37Z,[XLA:GPU] keep configs even if they occupy less than the available cores  We should not eliminate configs that under-occupy the available cores. The strategy leads to the configs with high split_k values and does not take into account cost of the follow up reduction fusion. Also for some kernels we don't accept the configs with some split_k because of the restrictions enforced in the split_k rewriter.  PiperOrigin-RevId: 780496018,42,0,42
tensorflow/tensorflow,8d1049b62ebcf1afae64b444ac0acf03d857ca39,Tori Baker,2025-07-08T10:22:01Z,"Fix ragged contracting mode to handle batch dimensions correctly  Before we were not handling the case correctly and it would crash due to incorrect shape at the end. Now, we properly transpose the group dim to the front of the final result.  Also, add tests to clarify this behavior  PiperOrigin-RevId: 780490452",67,15,82
tensorflow/tensorflow,cfd44e586dcc59f4030f283e9f4673dd5fabb86b,Henning Becker,2025-07-08T09:49:20Z,Add missing roctracer dependency to roctracer_wrapper target.  Otherwise all binaries that depend on roctracer_wrapper will fail to link with some undefined reference errors.  PiperOrigin-RevId: 780482037,1,0,1
tensorflow/tensorflow,0c8df04a7f64c68db2293832fd2c059c4def961d,dependabot[bot],2025-07-08T09:48:40Z,"PR #28591: Bump github/codeql-action from 3.29.1 to 3.29.2  Imported from GitHub PR https://github.com/openxla/xla/pull/28591  Bumps [github/codeql-action](https://github.com/github/codeql-action) from 3.29.1 to 3.29.2. <details> <summary>Release notes</summary> <p><em>Sourced from <a href=""https://github.com/github/codeql-action/releases"">github/codeql-action's releases</a>.</em></p> <blockquote> <h2>v3.29.2</h2> <h1>CodeQL Action Changelog</h1> <p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p> <h2>3.29.2 - 30 Jun 2025</h2> <ul> <li>Experimental: When the <code>quality-queries</code> input for the <code>init</code> action is provided with an argument, separate <code>.quality.sarif</code> files are produced and uploaded for each language with the results of the specified queries. Do not use this in production as it is part of an internal experiment and subject to change at any time. <a href=""https://redirect.github.com/github/codeql-action/pull/2935"">#2935</a></li> </ul> <p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.29.2/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p> </blockquote> </details> <details> <summary>Changelog</summary> <p><em>Sourced from <a href=""https://github.com/github/codeql-action/blob/main/CHANGELOG.md"">github/codeql-action's changelog</a>.</em></p> <blockquote> <h1>CodeQL Action Changelog</h1> <p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p> <h2>[UNRELEASED]</h2> <p>No user facing changes.</p> <h2>3.29.2 - 30 Jun 2025</h2> <ul> <li>Experimental: When the <code>quality-queries</code> input for the <code>init</code> action is provided with an argument, separate <code>.quality.sarif</code> files are produced and uploaded for each language with the results of the specified queries. Do not use this in production as it is part of an internal experiment and subject to change at any time. <a href=""https://redirect.github.com/github/codeql-action/pull/2935"">#2935</a></li> </ul> <h2>3.29.1 - 27 Jun 2025</h2> <ul> <li>Fix bug in PR analysis where user-provided <code>include</code> query filter fails to exclude non-included queries. <a href=""https://redirect.github.com/github/codeql-action/pull/2938"">#2938</a></li> <li>Update default CodeQL bundle version to 2.22.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2950"">#2950</a></li> </ul> <h2>3.29.0 - 11 Jun 2025</h2> <ul> <li>Update default CodeQL bundle version to 2.22.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2925"">#2925</a></li> <li>Bump minimum CodeQL bundle version to 2.16.6. <a href=""https://redirect.github.com/github/codeql-action/pull/2912"">#2912</a></li> </ul> <h2>3.28.19 - 03 Jun 2025</h2> <ul> <li>The CodeQL Action no longer includes its own copy of the extractor for the <code>actions</code> language, which is currently in public preview. The <code>actions</code> extractor has been included in the CodeQL CLI since v2.20.6. If your workflow has enabled the <code>actions</code> language <em>and</em> you have pinned your <code>tools:</code> property to a specific version of the CodeQL CLI earlier than v2.20.6, you will need to update to at least CodeQL v2.20.6 or disable <code>actions</code> analysis.</li> <li>Update default CodeQL bundle version to 2.21.4. <a href=""https://redirect.github.com/github/codeql-action/pull/2910"">#2910</a></li> </ul> <h2>3.28.18 - 16 May 2025</h2> <ul> <li>Update default CodeQL bundle version to 2.21.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2893"">#2893</a></li> <li>Skip validating SARIF produced by CodeQL for improved performance. <a href=""https://redirect.github.com/github/codeql-action/pull/2894"">#2894</a></li> <li>The number of threads and amount of RAM used by CodeQL can now be set via the <code>CODEQL_THREADS</code> and <code>CODEQL_RAM</code> runner environment variables. If set, these environment variables override the <code>threads</code> and <code>ram</code> inputs respectively. <a href=""https://redirect.github.com/github/codeql-action/pull/2891"">#2891</a></li> </ul> <h2>3.28.17 - 02 May 2025</h2> <ul> <li>Update default CodeQL bundle version to 2.21.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2872"">#2872</a></li> </ul> <h2>3.28.16 - 23 Apr 2025</h2> <ul> <li>Update default CodeQL bundle version to 2.21.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2863"">#2863</a></li> </ul> <h2>3.28.15 - 07 Apr 2025</h2> <ul> <li>Fix bug where the action would fail if it tried to produce a debug artifact with more than 65535 files. <a href=""https://redirect.github.com/github/codeql-action/pull/2842"">#2842</a></li> </ul> <h2>3.28.14 - 07 Apr 2025</h2> <!-- raw HTML omitted --> </blockquote> <p>... (truncated)</p> </details> <details> <summary>Commits</summary> <ul> <li><a href=""https://github.com/github/codeql-action/commit/181d5eefc20863364f96762470ba6f862bdef56b""><code>181d5ee</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2957"">#2957</a> from github/update-v3.29.2-4c57370d0</li> <li><a href=""https://github.com/github/codeql-action/commit/c77386a9db782647c8e2575da69a3c950786eaca""><code>c77386a</code></a> Fix changelog PR number</li> <li><a href=""https://github.com/github/codeql-action/commit/8d43d4ecec27cc4205b0eaaf2e9b4bf9ee9a305b""><code>8d43d4e</code></a> Update changelog for v3.29.2</li> <li><a href=""https://github.com/github/codeql-action/commit/4c57370d0304fbff638216539f81d9163f77712a""><code>4c57370</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2935"">#2935</a> from github/mbg/interpret-cq-results</li> <li><a href=""https://github.com/github/codeql-action/commit/2830b750e5012e0a57cb63888cd5720f2326ca5c""><code>2830b75</code></a> Add changelog entry</li> <li><a href=""https://github.com/github/codeql-action/commit/aa72ddaeada556e7d763c9a0afb01f2c2a365e1c""><code>aa72dda</code></a> Merge branch 'main' into mbg/interpret-cq-results</li> <li><a href=""https://github.com/github/codeql-action/commit/65d1e45f0ba420207efc0f1f6d90c63dcbc97551""><code>65d1e45</code></a> Rename <code>SARIF_UPLOAD_ENDPOINT</code> members</li> <li><a href=""https://github.com/github/codeql-action/commit/362ebf85dad6ee3df420db2cec285490b289a61f""><code>362ebf8</code></a> Check both SARIF files in <code>quality-queries.yml</code> test</li> <li><a href=""https://github.com/github/codeql-action/commit/10a3e4b17dd8a1cee767213c309bd4b1e8251eab""><code>10a3e4b</code></a> Fix formatting</li> <li><a href=""https://github.com/github/codeql-action/commit/8593ea65e2bf97ec2caa80fb0e464ed8c42c0fae""><code>8593ea6</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2954"">#2954</a> from github/mergeback/v3.29.1-to-main-39edc492</li> <li>Additional commits viewable in <a href=""https://github.com/github/codeql-action/compare/39edc492dbe16b1465b0cafca41432d857bdb31a...181d5eefc20863364f96762470ba6f862bdef56b"">compare view</a></li> </ul> </details> <br />  [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=github/codeql-action&package-manager=github_actions&previous-version=3.29.1&new-version=3.29.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)  Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.  [//]: # (dependabot-automerge-start) [//]: # (dependabot-automerge-end)  ---  <details> <summary>Dependabot commands and options</summary> <br />  You can trigger Dependabot actions by commenting on this PR: - `@dependabot rebase` will rebase this PR - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it - `@dependabot merge` will merge this PR after your CI passes on it - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it - `@dependabot cancel merge` will cancel a previously requested merge and block automerging - `@dependabot reopen` will reopen this PR if it is closed - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself) - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself) - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)  </details> Copybara import of the project:  -- 908f5234414c30c561fcff2ed8bff5d86c4e3440 by dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>:  Bump github/codeql-action from 3.29.1 to 3.29.2  Bumps [github/codeql-action](https://github.com/github/codeql-action) from 3.29.1 to 3.29.2. - [Release notes](https://github.com/github/codeql-action/releases) - [Changelog](https://github.com/github/codeql-action/blob/main/CHANGELOG.md) - [Commits](https://github.com/github/codeql-action/compare/39edc492dbe16b1465b0cafca41432d857bdb31a...181d5eefc20863364f96762470ba6f862bdef56b)  --- updated-dependencies: - dependency-name: github/codeql-action   dependency-version: 3.29.2   dependency-type: direct:production   update-type: version-update:semver-patch ...  Signed-off-by: dependabot[bot] <support@github.com>  Merging this change closes #28591  PiperOrigin-RevId: 780481889",1,1,2
tensorflow/tensorflow,2998e2fc373f88f82717324e679a259dfd262f50,A. Unique TensorFlower,2025-07-08T09:04:57Z,Automated Code Change  PiperOrigin-RevId: 780468639,2,0,2
tensorflow/tensorflow,eaff8611ce194b2d9515bc09e88db80443679bc0,A. Unique TensorFlower,2025-07-08T09:03:27Z,compat: Update forward compatibility horizon to 2025-07-08  PiperOrigin-RevId: 780468040,1,1,2
tensorflow/tensorflow,b72ff409f8b1a37b1e2c1e42021aa310e1e95e5c,A. Unique TensorFlower,2025-07-08T09:03:20Z,Update GraphDef version to 2282.  PiperOrigin-RevId: 780467978,1,1,2
tensorflow/tensorflow,7756dde61b6c8bf14fa710ae4d04105766c75d15,A. Unique TensorFlower,2025-07-08T08:12:07Z,Automated Code Change  PiperOrigin-RevId: 780452074,7,0,7
tensorflow/tensorflow,768132a371e698b19f6e84476058efe5b7099c04,A. Unique TensorFlower,2025-07-08T06:27:08Z,Automated Code Change  PiperOrigin-RevId: 780421697,0,1,1
tensorflow/tensorflow,dda32a9e6fb7b7fc6ad04930aacd8c7fa7dc6f42,A. Unique TensorFlower,2025-07-08T06:15:19Z,Set XNN_FLAG_SLINKY_STATIC_BOUNDS in xnn_fusion_thunk.  PiperOrigin-RevId: 780419314,7,6,13
tensorflow/tensorflow,91ab614afbf781485ad1e90ac354572b787ca9c7,A. Unique TensorFlower,2025-07-08T05:59:12Z,Automated Code Change  PiperOrigin-RevId: 780415084,2,0,2
tensorflow/tensorflow,86086ebaf314fa15922d395c39a45a03d109c7d1,A. Unique TensorFlower,2025-07-08T05:54:55Z,Automated Code Change  PiperOrigin-RevId: 780413917,7,0,7
tensorflow/tensorflow,958b0461b38f83442b9a0978af037f18d1e36e02,A. Unique TensorFlower,2025-07-08T04:44:59Z,Automated Code Change  PiperOrigin-RevId: 780396029,1,0,1
tensorflow/tensorflow,521ebee4b404618f353103cbe720ea8fe295952b,A. Unique TensorFlower,2025-07-08T03:22:19Z,Use the output shape from executables when minting error buffers  PiperOrigin-RevId: 780373769,46,5,51
tensorflow/tensorflow,aed591737aa31b0a8ec342678f8e4eeec5d9a00c,Haibo Huang,2025-07-08T02:28:31Z,Call get_logical_on_device_shape within thread pool.  PiperOrigin-RevId: 780357026,31,22,53
tensorflow/tensorflow,e2e1ae8fd027c9bdd6e75181e0d5aaaa6a7a12c6,Emily Fertig,2025-07-08T01:04:49Z,[JAX] Use experimental DCN transfer library as a fallback for PjRt-IFRT cross-host device transfers when the PjRt plugin doesn't implement the cross-host transfer APIs.  PiperOrigin-RevId: 780333956,323,13,336
tensorflow/tensorflow,62968adaad04bff0ea48123d77e07f2687e3f4c0,A. Unique TensorFlower,2025-07-08T00:56:33Z,"Don't try to handle batched dot products.  XNNPACK's `xnn_define_batch_matrix_multiply` can't handle this case, because it interprets the batch dimensions as matrix dimensions.  Previously, we accidentally avoided this bug due to the heuristic to avoid using XNNPACK when we want to tile K, but we should handle this case explicitly.  PiperOrigin-RevId: 780330672",34,0,34
tensorflow/tensorflow,1baf31fd0fe36fced33c6a6f29a68499e63535d8,Tom Natan,2025-07-08T00:56:13Z,[StableHLO] Bump the 4 week compatibility version to 1.11.0  PiperOrigin-RevId: 780330580,25,12,37
tensorflow/tensorflow,3c371226f57354ac8024f0feccf0b14ea7743336,A. Unique TensorFlower,2025-07-07T23:49:02Z,Update XNNPACK to get new APIs  PiperOrigin-RevId: 780310627,10,10,20
tensorflow/tensorflow,d76776c9f27571503a8ed20225799dc6f18c03b1,A. Unique TensorFlower,2025-07-07T23:37:45Z,#HLODiff Add bipartite matching to GreedyTopDownMatcher.  PiperOrigin-RevId: 780307215,103,72,175
tensorflow/tensorflow,9cdb2874a96c244cf138c79516e981f9fb93e596,David Pizzuto,2025-07-07T23:35:58Z,build: Set is_ci flag in OSS CI.  This flag is set on internal CI and has a handful of effects that should be consistent between internal and OSS.  PiperOrigin-RevId: 780306688,50,36,86
tensorflow/tensorflow,882725079a5ab6ece25801ea797775d36a60b07b,A. Unique TensorFlower,2025-07-07T23:12:47Z,Update XNNPACK to get new APIs  PiperOrigin-RevId: 780299042,3,3,6
tensorflow/tensorflow,24c2972bdcee3d159f4c72d57ff1c7be8a100e54,A. Unique TensorFlower,2025-07-07T23:08:52Z,"Fixes the issue when the RaggedFeature partition class type is not correctly parsed when cloud pickle unpickles the object.  This is a workaround for the problem that cloudpickle does not correctly keep the class types for nested classes, particularly for the RaggedFeature Partition class types: `RowSplits`, `RowLengths`, etc.  PiperOrigin-RevId: 780297578",240,8,248
tensorflow/tensorflow,3568971ba7e356e7c25c759cc27a19a01765b4b5,A. Unique TensorFlower,2025-07-07T22:55:55Z,#HLODiff Add tiny bonus to position match  PiperOrigin-RevId: 780292554,92,80,172
tensorflow/tensorflow,91dfafc0f375146b043e9192505ff541d98c25db,Daniel Sosa,2025-07-07T22:29:17Z,Create new CI configurations  PiperOrigin-RevId: 780282923,2,2,4
tensorflow/tensorflow,9e90079b82adeb0a41e0f351611fb31a2baf8087,Jae H. Yoo,2025-07-07T22:05:20Z,Support boolean tensor in pad and padV2 ops.  PiperOrigin-RevId: 780274760,104,15,119
tensorflow/tensorflow,e10d5f9e3073eb6459b460416be7a82c7f17cc0b,A. Unique TensorFlower,2025-07-07T20:34:03Z,Use schedule order to calculate resource usage.  PiperOrigin-RevId: 780239376,107,69,176
tensorflow/tensorflow,90ac04aaf4d7ed525db82ecb07f4786cc6be9afd,Ezekiel Calubaquib,2025-07-07T20:28:51Z,fixed missing .so files in tf wheel audit  PiperOrigin-RevId: 780237252,12,8,20
tensorflow/tensorflow,c6dae4670ae3c84a0d2781d805a8b7e3d66aa61c,Ibrahim Umit Akgun,2025-07-07T19:51:51Z,[XLA] Refactoring Reduce Window Rewriter to reduce complexity  Reshaping/Expanding the new major dimension (Complexity 47 -> 46)  PiperOrigin-RevId: 780223245,77,53,130
tensorflow/tensorflow,0cce95628d3f0bbd36f59bd6984b25aeb9c5d27d,Daniel Chen,2025-07-07T18:58:54Z,[ #HLODiff ] Refine computation diff.  - Add color decoration for unmatched/changed instructions. - Support unmatched computation - Update text to summarize diff pattern - Show the sample diff by default  PiperOrigin-RevId: 780203634,220,116,336
tensorflow/tensorflow,a3cd1692f8b816786b161aa272646c419a7192c5,Steeve Morin,2025-07-07T18:33:15Z,"Add `-Wl,-install_name,@rpath/pjrt_c_api_cpu_plugin.dylib` to `pjrt_c_api_cpu_plugin.so` linkopts on MacOS  This closes  https://github.com/openxla/xla/pull/16696  PiperOrigin-RevId: 780193030",1,0,1
tensorflow/tensorflow,ef67195be74007b79e44edfa6fbc58387cab1d1f,Michael Whittaker,2025-07-07T18:04:09Z,Remove old heartbeat options.  PiperOrigin-RevId: 780180128,0,25,25
tensorflow/tensorflow,c9abef3364b72eabaad06d555f1c81179b3c288c,Daniel Chen,2025-07-07T17:52:44Z,[ #HLODiff ] Sort diff patterns by diff size instead of group size.  PiperOrigin-RevId: 780175500,12,4,16
tensorflow/tensorflow,61ec7bff6779048b95efc50db360636344d230d7,Daniel Chen,2025-07-07T17:24:25Z,[ #HLODiff ] Filter ignored opcodes before rendering results.  Note that the numbers in the summary are pre-calculated so it won't add up to the number in the full diff.  PiperOrigin-RevId: 780164035,155,49,204
tensorflow/tensorflow,20628a1e6b225c040cce3b23411e7000d27ba692,Parker Schuh,2025-07-07T16:41:51Z,Add CopyToRemote() to CommonPjRtBufferImpl.  PiperOrigin-RevId: 780147200,71,0,71
tensorflow/tensorflow,95764eef0baefd9ebbf124a2b77eda181b47f8dd,Henning Becker,2025-07-07T15:32:16Z,"Fix stack-use-after-scope in cudnn_custom_call_compiler  stream_executor::gpu::ScoreModFunc was allocated in the stack but its pointer was passed to CreateForwardMultiheadAttention, which stores a reference to it. PiperOrigin-RevId: 780123525",5,4,9
tensorflow/tensorflow,6d11ec0000e8847153ff9920049a522786ad553d,Aliia Khasanova,2025-07-07T14:25:44Z,"[XLA:GPU] Don't convert thunks into command buffer, if amount of thunks is less then `xla_gpu_graph_min_graph_size`.  PiperOrigin-RevId: 780101082",36,1,37
tensorflow/tensorflow,c96fdef4a3bcbc1ac1255888098bfb39f01a134b,Alexander Lyashuk,2025-07-07T13:01:09Z,[XLA:GPU] ShapeUtil::InsertDimensionsAtIndex utility function to insert multiple dimensions to a shape.  And update layout accordingly.  PiperOrigin-RevId: 780077150,53,9,62
tensorflow/tensorflow,3eefc4a2ee5dd6d3b7c8f5ebe68b786d1522a41e,Sohaib Iftikhar,2025-07-07T12:46:42Z,[XLA:GPU]: Fix issues in two-shot kernel implementation  The two-shot kernel was mixing grid-stride and block-stride loops. This lead to the same thread working on different indices in some cases. This change unifies all loops to use the block-stride for uniformity.  PiperOrigin-RevId: 780073109,50,31,81
tensorflow/tensorflow,bdbd0c4bab1e23023b7e4da70326fff99a235d23,Adrian Kuegel,2025-07-07T10:24:06Z,"Pass HloAliasAnalysis and AliasInfo to MinimumMemoryForModule().  All callers already have computed HloAliasAnalysis, not passing it means needlessly recomputing it. Also, we should have the proper AliasInfo when running HeapSimulator. Remove report_total_fragmentation parameter of StatsString(), it was always set to true by the callers.  PiperOrigin-RevId: 780033241",64,49,113
tensorflow/tensorflow,f94dcde509b18d3092337a221374f65e0651ed13,A. Unique TensorFlower,2025-07-07T09:03:07Z,compat: Update forward compatibility horizon to 2025-07-07  PiperOrigin-RevId: 780010169,1,1,2
tensorflow/tensorflow,61fdfd5d214a619bd1c1a71af1cdfc0f296c56ef,A. Unique TensorFlower,2025-07-07T09:02:53Z,Update GraphDef version to 2281.  PiperOrigin-RevId: 780010032,1,1,2
tensorflow/tensorflow,bb4c92129ecf49210ef2b9bcd38c437aea2cb8e1,Allan Renucci,2025-07-07T08:29:34Z,Sort and remove duplicate symbols.  PiperOrigin-RevId: 779998824,837,1220,2057
tensorflow/tensorflow,6991f6e761db28f3b7b6fe98cfe0142ac8021ab1,Tori Baker,2025-07-07T07:45:50Z,"Add Ragged Dot Extra LHS dim test.  new_dim_index is where we expand the matrix. At the index of the size of the group_sizes matrix - 1 makes sense because the last dim of group_sizes is always the one that represents the group and the ones before that are either extra dims that also appear in the matrices that get expanded (such as other non-contracting lhs dims if in NonContracting mode, contracting lhs/rhs dims is in contracting mode, or batch dims).  PiperOrigin-RevId: 779986546",28,5,33
tensorflow/tensorflow,2e59f111f617cd3cd0fc6c2fd2f12b278892adf7,A. Unique TensorFlower,2025-07-07T06:44:15Z,Automated Code Change  PiperOrigin-RevId: 779968611,11,1,12
tensorflow/tensorflow,374caea2d913bb103d252c790822a9cea28379fe,Tori Baker,2025-07-07T06:40:47Z,Add e2e ragged dot test for gpu  PiperOrigin-RevId: 779967682,129,0,129
tensorflow/tensorflow,f36f290a5e9b9202a78db12a2af7a4b74d2a32ab,A. Unique TensorFlower,2025-07-07T05:47:11Z,"If a host xpose copy goes into a host-call, the copy cannot be moved.  PiperOrigin-RevId: 779954523",34,1,35
tensorflow/tensorflow,3fe86c28d2ef0ffdd8fd71a8ba323d22a13a40b4,Michael Kuperstein,2025-07-06T21:53:25Z,[XLA] Add should_inline callback to CallInliner  Add a callback to CallInliner to allow finer-grained control over which callsites to inline.  PiperOrigin-RevId: 779849022,75,6,81
tensorflow/tensorflow,37d758b8cbcfcb4cf9962368204c74a675edd49c,A. Unique TensorFlower,2025-07-06T17:21:48Z,No public description  PiperOrigin-RevId: 779797363,169,70,239
tensorflow/tensorflow,faa8c915286c480e05a97856dbaa22decaf96c22,A. Unique TensorFlower,2025-07-06T09:03:24Z,compat: Update forward compatibility horizon to 2025-07-06  PiperOrigin-RevId: 779703950,1,1,2
tensorflow/tensorflow,2bf9d0ed713e389d2720525d822a871d8acbf7fc,A. Unique TensorFlower,2025-07-06T09:03:06Z,Update GraphDef version to 2280.  PiperOrigin-RevId: 779703854,1,1,2
tensorflow/tensorflow,73d14f70faa4195e64cae8a39e42ae520ba1d4bf,A. Unique TensorFlower,2025-07-05T09:02:55Z,compat: Update forward compatibility horizon to 2025-07-05  PiperOrigin-RevId: 779426290,1,1,2
tensorflow/tensorflow,cd62b2cd92783df5d02f464430f16838490bd936,A. Unique TensorFlower,2025-07-05T09:02:55Z,Update GraphDef version to 2279.  PiperOrigin-RevId: 779426286,1,1,2
tensorflow/tensorflow,b6becac2a753aa381e0a61ed90ddbf7f4a5eaf2e,Allan Renucci,2025-07-05T05:13:33Z,Manually migrate deprecated references to `strings::StrCat` and `strings::StrAppend`.  `strings::StrCat` and `strings::StrAppend` should eventually forward to `absl::StrCat` and `absl::StrAppend`. Some references need to be rewritten as `absl::StrCat(absl::LegacyPrecision(...))` to avoid loss of precision.  This is a no-op change.  PiperOrigin-RevId: 779378826,562,549,1111
tensorflow/tensorflow,67dc6b1ff052a54760a2b57cc479d929f8213990,Eugene Zhulenev,2025-07-04T19:33:50Z,[xla:cpu] Delete unused files  PiperOrigin-RevId: 779254693,0,149,149
tensorflow/tensorflow,460168aa3f143c897a0249109f094f4104ef299c,Tom Natan,2025-07-04T19:18:29Z,#sdy move remove-size-one-axes pass to Shardy import pipeline.  PiperOrigin-RevId: 779251485,894,8388,9282
tensorflow/tensorflow,6a3b4888522acbc6137d222e7f5fe9693ee914d7,Mikhail Goncharov,2025-07-04T17:03:31Z,"[XLA:GPU] partial revert of ""don't fail in autotuner if a specific config does not fly""  Currently nest_gemm_fusion gracefully fails and does not rewrite the module when it cannot tile it.  Making autotuner fail on all cases again as it should not see errors from the new pass anymore.  PiperOrigin-RevId: 779221727",0,6,6
tensorflow/tensorflow,8dd6ebb6ece4d776287aad0b27ae4c2be8e681f9,Alexander Belyaev,2025-07-04T16:12:59Z,[XLA:GPU][Tiling] Add tiling propagation for dyn-slice.  PiperOrigin-RevId: 779209608,200,54,254
tensorflow/tensorflow,c9e37b62765066529b5b8f6f4ae345349695f1bf,Adrian Kuegel,2025-07-04T14:28:20Z,Remove some leftovers of sparse dot support in GemmFusion (NFC).  PiperOrigin-RevId: 779183586,3,16,19
tensorflow/tensorflow,ccb6365e1baf0cd4c7ce6808e807eb64ca4f0b64,Allan Renucci,2025-07-04T13:38:03Z,Use `absl::NoDestructor` in more places.  PiperOrigin-RevId: 779170692,101,83,184
tensorflow/tensorflow,dcd6ea72dbcf7f7b1135bd0c0d9049a8b035bb5b,Karlo Basioli,2025-07-04T13:06:05Z,[XLA:CPU][nanort] Test that compilation pipeline propagates int4 packing information to executable.  PiperOrigin-RevId: 779163104,31,0,31
tensorflow/tensorflow,129a83549630435ce93fb5690b87e12f117a2ad8,Aliia Khasanova,2025-07-04T12:52:01Z,"[XLA:GPU] Support command buffer conversion for async operations on thunks level.  * Add virtual method `GetAsyncEventsUniqueId()` to Thunk interface. All derived classes, that represent thunks for async operations should override it. This is required to be able to find pairs of (async-start, async-done).  * Followed general logic in `command_buffer_scheduling` to detect async regions  * include_cleaner & build_cleaner on all touched files.  PiperOrigin-RevId: 779159549",637,96,733
tensorflow/tensorflow,2d14f598704d94379a8a6ba8d14bc4c9503453ce,Tori Baker,2025-07-04T12:41:03Z,"Do not populate floating point data with nans  At the moment, it's possible to generate 0 for floating point data with the max_bits_of_precision argument. With the normalization that happens, this can then transform into a nan if it's 0, when it should just be 0.  PiperOrigin-RevId: 779156801",3,2,5
tensorflow/tensorflow,b211863e832b3cac9fb9ebe10cbb3b468a8f0714,Adrian Kuegel,2025-07-04T12:09:57Z,Remove unused parameter (NFC).  PiperOrigin-RevId: 779149264,4,11,15
tensorflow/tensorflow,b5eaf8b8b95eef58c877be22c49424f0661755f9,dependabot[bot],2025-07-04T11:09:25Z,Bump setuptools in /ci/official/requirements_updater/numpy1_requirements  Bumps [setuptools](https://github.com/pypa/setuptools) from 70.0.0 to 78.1.1. - [Release notes](https://github.com/pypa/setuptools/releases) - [Changelog](https://github.com/pypa/setuptools/blob/main/NEWS.rst) - [Commits](https://github.com/pypa/setuptools/compare/v70.0.0...v78.1.1)  --- updated-dependencies: - dependency-name: setuptools   dependency-version: 78.1.1   dependency-type: direct:production ...  Signed-off-by: dependabot[bot] <support@github.com>,13,13,26
tensorflow/tensorflow,5aba95bf870cb9fcce8b0ece195d7e6cb0272c8e,dependabot[bot],2025-07-04T11:09:01Z,Bump requests in /ci/official/requirements_updater/numpy1_requirements  Bumps [requests](https://github.com/psf/requests) from 2.32.3 to 2.32.4. - [Release notes](https://github.com/psf/requests/releases) - [Changelog](https://github.com/psf/requests/blob/main/HISTORY.md) - [Commits](https://github.com/psf/requests/compare/v2.32.3...v2.32.4)  --- updated-dependencies: - dependency-name: requests   dependency-version: 2.32.4   dependency-type: direct:production ...  Signed-off-by: dependabot[bot] <support@github.com>,12,12,24
tensorflow/tensorflow,a3118a9229a0a4bea656315e2a08938e59876099,TensorFlower Gardener,2025-07-04T11:06:42Z,Merge pull request #96246 from tensorflow:dependabot/pip/ci/official/requirements_updater/numpy1_requirements/urllib3-2.5.0  PiperOrigin-RevId: 779128540,12,12,24
tensorflow/tensorflow,1c07e0bec7a86a6cd9762c96cf444ab56c139f96,TensorFlower Gardener,2025-07-04T10:55:23Z,Merge pull request #84874 from Intel-tensorflow:gaurides/fp16_last_compute  PiperOrigin-RevId: 779127744,47,9,56
tensorflow/tensorflow,4bba92fada7a7f51104cf49e27b6510282e7c982,TensorFlower Gardener,2025-07-04T10:42:27Z,Merge pull request #96243 from tensorflow:dependabot/github_actions/github-actions-b58c86cf64  PiperOrigin-RevId: 779124151,2,2,4
tensorflow/tensorflow,589067f2309593863007aa5052c92d5a08a4f360,Henning Becker,2025-07-04T09:51:18Z,"Add some very slow algorithms to the cuDNN algorithm deny list  Engine 0 is sometimes really slow - in these cases it takes minutes instead of seconds. So I'm putting the relevant cases on the deny list.  I've also tried excluding engine 0 if other options are available but as it turns out there are cases where engine 0 is the better option over the more specialized other engines, so we can't do that.  PiperOrigin-RevId: 779113135",31,0,31
tensorflow/tensorflow,2161abfed67c13e649b6d1b698cf1a0137dabb01,Henning Becker,2025-07-04T09:25:32Z,Remove GOOGLE_CUDA macro usage from conv_algorithm_picker  PiperOrigin-RevId: 779106041,6,28,34
tensorflow/tensorflow,4ba00881df34da576175a03323bee4e2f4fb482d,A. Unique TensorFlower,2025-07-04T09:03:45Z,compat: Update forward compatibility horizon to 2025-07-04  PiperOrigin-RevId: 779099746,1,1,2
tensorflow/tensorflow,ea7b28944d8add5e90919089e1183770283524aa,A. Unique TensorFlower,2025-07-04T09:03:27Z,Update GraphDef version to 2278.  PiperOrigin-RevId: 779099640,1,1,2
tensorflow/tensorflow,4c84d72525d02a389a6689d338c3723689be31b2,Henning Becker,2025-07-04T08:53:00Z,"Make HloAlgorithmDenylist more robust and more testable  The main interaction for the denylist is the function `GetDisabledConvAlgorithms` which used to take an HLO string for matching against the denylist. But it wasn't specified how this string was supposed to be formatted. Turns out it needs to be formatted in the ""fingerprint with backend config"" - which is not what was passed in by the autotuner. That means this code was not working at all.  I changed the function so that it takes a `HloCustomCallInstruction` reference instead and creates its own string representation which makes the usage more robust.  I also factored out the parsing of the denylist, so that tests can inject arbitrary denylists without messing with the XLA flags.  In addition I added a function which can create a deny list entry from a HloCustomCallInstruction. This helps with creating new denylist entry. This deny list entry gets v-logged at level 5 automatically for every convolution the autotuner tries.  PiperOrigin-RevId: 779096372",279,87,366
tensorflow/tensorflow,54ccd720ccff7ebe5d9a44de7515804a9b21b2ec,Eugene Zhulenev,2025-07-04T04:13:36Z,[xla:cpu] Delete unused files  PiperOrigin-RevId: 779034101,0,2,2
tensorflow/tensorflow,5fbacc7c927b266cc8e7c63742a555273e78fc52,Marcello Maggioni,2025-07-04T01:55:39Z,"[XLA] Fix typo in LHS causing bug  We introduced a new kind of kForceDelay to use it, but we weren't. Fixing that and make sure test catches behavior  PiperOrigin-RevId: 779004434",54,2,56
tensorflow/tensorflow,02654bc77562121f0a89d045fc37d20c14c84343,Eric Yang,2025-07-04T01:14:54Z,"Modify MLIR location of TFLite op to contain TFLite tensor names  **On Import**: The original debug location is wrapped in a new `FusedLoc`. This wrapper contains `NameLoc`(s) for the TFLite tensor name(s) and a ""tflite.importer_wrapper"" marker. This makes the TFLite tensor names directly accessible while preserving the original debug info.  **On Export**: The wrapper `FusedLoc` is identified by its marker and removed. The original, unwrapped location is then serialized, ensuring roundtrip fidelity.  Example Location Structure:  Before (in MLIR): The op's location is the raw debug info from the flatbuffer, which may already be a FusedLoc from a prior conversion (e.g., PyTorch -> TFLite). ``` FusedLoc([NameLoc(""pytorch_op_1""), NameLoc(""pytorch_op_2"")]) ``` After (in MLIR): The location is wrapped to include the TFLite tensor name. The original location becomes the child of a new NameLoc. ``` FusedLoc(     [NameLoc(""tflite_tensor_name"", FusedLoc([NameLoc(""pytorch_op_1""), NameLoc(""pytorch_op_2"")]))],     ""tflite.importer_wrapper"" ) ```  PiperOrigin-RevId: 778998798",211,68,279
tensorflow/tensorflow,a43e9bc2df8a8427ddcff67fbdd7b3bc2ca1abec,A. Unique TensorFlower,2025-07-03T22:31:33Z,Remove tsl_workspace*.bzl files in XLA.  Move the deps into the regular workspace*.bzl files instead. The tsl_* files no longer serve any purpose and only cause obfuscation and duplication.  PiperOrigin-RevId: 778970015,556,863,1419
tensorflow/tensorflow,bb7f93470dfe76b93d8a48850b8b1c9c6079f01b,Eugene Zhulenev,2025-07-03T22:24:09Z,[xla:cpu] Parallelize matrix-vector products  Use workgroup dimensions x and y to parallelize matrix-vector products.  PiperOrigin-RevId: 778969024,362,119,481
tensorflow/tensorflow,0921e2691f4985d3c11ee5a77cc0d4a779ebcf33,Shahriar Rouf,2025-07-03T20:45:34Z,Optimize `mlir::ConvertMlirHloToHlo` by moving the proto from the `XlaComputation` local variable in `mlir::ConvertToHloModule::ConsumeMainProto`.  Check out this generated assembly diff: https://godbolt.org/z/rWYv3d917.  PiperOrigin-RevId: 778953276,1,1,2
tensorflow/tensorflow,25fb90f449c976f8e396dddf8a656381dc7d2996,Hyeontaek Lim,2025-07-03T20:07:45Z,"[IFRT Proxy] Change loaded host callback polling to use continuation to avoid holding a thread when blocked for the poll response  Loaded host callbacks currently use polling from the IFRT Proxy client side with RPC. With the response to the RPC request, it takes a callback execution request from the IFRT Proxy server, processes it on the IFRT Proxy client, and send the result back to the server.  This process currently holds a thread throughout, which requires one thread per loaded host callback.  This change relaxes the thread requirement. The client makes the polling RPC request non-blocking by setting up future OnReady callback without synchronous blocking. Upon receiving a polling RPC response, it then uses the global thread pool for procesisng the RPC response handling and the actual callback execution. The next polling is then scheduled using a continuation pattern.  PiperOrigin-RevId: 778946979",95,77,172
tensorflow/tensorflow,267368232dc22a37f9af35bd33aaa5a4ca36174b,Shaogang Wang,2025-07-03T19:32:11Z,"PR #28471: [XLA:GPU] allow lowering DynamicMemCopy thunk when it depends on loop iteration  Imported from GitHub PR https://github.com/openxla/xla/pull/28471  This PR enables lowering DynamicMemCopy thunk to command buffer, if it depends on loop iteration.  This introduce a scenario where even buffer allocations are not changed, the command buffer still needs to be updated,  because the memory pointer that is consumed by cuda-graph nodes are sliced with loop iteration index.  Copybara import of the project:  -- 5acd220701b4e78ed9de5a8ae94062bd1ddf767f by Shawn Wang <shawnw@nvidia.com>:  Lower DynamicSliceCopyFusion command buffer command even if it depends on loop iteration  Merging this change closes #28471  PiperOrigin-RevId: 778941437",206,37,243
tensorflow/tensorflow,b289d99903f498e21f27cef2ad063176647e77e8,Chenhao Jiang,2025-07-03T19:19:32Z,"PR #28497: Create cudnn handle for all threads to reuse during cudnn compilation  Imported from GitHub PR https://github.com/openxla/xla/pull/28497  When multiple threads invoke cudnnCreate api in cuda_dnn.cc::GetLocalHandle() in the one-process-per-gpu setting, it causes a hang of 6-7 seconds, which causes a significant compilation overhead when `--xla_gpu_enable_triton_gemm=true` and `--xla_gpu_cudnn_gemm_fusion_level=1` is set on blackwell GPUs. This PR creates a separate handle for cudnn plan compilation only and reuses the same handle across threads. Copybara import of the project:  -- 618d0aa259d542e41766320561c4957bf0deff79 by Chenhao Jiang <chenhaoj@nvidia.com>:  Create cudnn handle for all threads to reuse during cudnn compilation  Merging this change closes #28497  PiperOrigin-RevId: 778939397",28,25,53
tensorflow/tensorflow,e6864e208186bf6bdd9118ce961419015e2f80ad,Christian Sigg,2025-07-03T19:15:59Z,[XLA:GPU] NFC: slightly improve TritonXLAExtractInsertToTritonPass.  - Move `Option` to the derived pass class. This allows a custom parser and we don't need to store a string or update a member in `runOnOperation()`.  - Mark 'private' what can be private.  - Move pass definition out of anonymous namespace. There might be symbols declare by the decl in the header file. The base pass itself is defined in the impl namespace for this reason.  - Remove the unused default factory method arguments.  PiperOrigin-RevId: 778938786,65,48,113
tensorflow/tensorflow,609693e040989e60650a3245a0aa4e2c8984ecb8,Siddhartha Menon,2025-07-03T19:15:20Z,PR #28487: chore: add Arm Limited to AUTHORS  Imported from GitHub PR https://github.com/openxla/xla/pull/28487  add Arm Limited to AUTHORS Copybara import of the project:  -- 01f314cfbf72edec1d2c8d1f00da36904626009b by Siddhartha Menon <siddhartha.menon@arm.com>:  chore: add Arm Limited to AUTHORS  Signed-off-by: Siddhartha Menon <siddhartha.menon@arm.com>  Merging this change closes #28487  PiperOrigin-RevId: 778938693,2,1,3
tensorflow/tensorflow,3d706b64478c3f3a35908570dcd9c0f4549055c4,Buddh Prakash,2025-07-03T18:47:58Z,Optimize DiceSimLimitedSubgraph by pre allocating vectors.  PiperOrigin-RevId: 778933639,19,7,26
tensorflow/tensorflow,4c39f79e9f0d74bfc3befb71a7f0f0e7e1906a58,Junwhan Ahn,2025-07-03T16:33:07Z,Mark `PjRtFuture::IsReady` and `PjRtFuture::IsKnownReady` as `const`  PiperOrigin-RevId: 778909527,2,2,4
tensorflow/tensorflow,39c66e2ff625d6d68b3b515849929b82978aa681,Jesse Rosenstock,2025-07-03T16:03:11Z,kernels: Remove use of icu::UnicodeStringAppendable  UnicodeStringAppendable is not needed.  icu::UnicodeString can also be appended to.  #Cleanup  PiperOrigin-RevId: 778903841,2,4,6
tensorflow/tensorflow,be1c6bfcf5ebbaf3efd06169256a4cc27ad01c57,A. Unique TensorFlower,2025-07-03T14:48:17Z,Integrate LLVM at llvm/llvm-project@696c0f92e0fe  Updates LLVM usage to match [696c0f92e0fe](https://github.com/llvm/llvm-project/commit/696c0f92e0fe)  PiperOrigin-RevId: 778888035,8767,4054,12821
tensorflow/tensorflow,8e8cc31f79648e8b0ca296d4da1c5165c976e46c,Aliia Khasanova,2025-07-03T14:09:22Z,"Port `ThunkPassPipeline` with `CommandBufferConversionPass` into gpu_compiler. Introduce a flag, that switches creation of command buffers from HLO level to Thunk level. This is a temporary flag to provide a smooth transition.  PiperOrigin-RevId: 778879974",92,5,97
tensorflow/tensorflow,3ccbfebb0257fd00fe6617ec14dc2899ca08507e,Mikhail Goncharov,2025-07-03T12:31:06Z,[XLA:GPU] do not fail in nest gemm fusion if we cannot convert the computation  As part of rollout process of the new emitter we plan to allow both new and legacy emitters to coexist. That means that nest gemm fusion will sometimes receive HLO computations we don't currently support in the generic emitter / symbolic analysis / etc.  Now the pass tries to modify the clone of the module first and make changes on success.  Also removed the check that legacy emitter must not be used if generic dot emitter is enabled.  PiperOrigin-RevId: 778857902,52,33,85
tensorflow/tensorflow,094ebe6cf660eeacb18d5ae5f5350513fb000be9,Alexander Lyashuk,2025-07-03T11:35:12Z,[XLA:GPU] Add DotOperandDims::InsertDimension()  PiperOrigin-RevId: 778845379,85,0,85
tensorflow/tensorflow,2d31a1985404941c52cb394e2d459561ef8411da,Bart Chrzaszcz,2025-07-03T11:28:35Z,#sdy #mixed_serialization don't make JAX export use `SdyRoundTripExportPipeline` to stringify attributes and convert ops to StableHLO `CustomCallOp`s and back.  Instead keep every op as is now that StableHLO supports serialization with different dialects in the MLIR module.  PiperOrigin-RevId: 778844006,40,1,41
tensorflow/tensorflow,48028cbd4a9db1ff1161b44e7b5c88ce25041cb1,Allan Renucci,2025-07-03T10:51:57Z,[XLA:GPU] Remove `ScheduleGpuModuleWithMemoryScheduler` from public API.  PiperOrigin-RevId: 778835017,39,98,137
tensorflow/tensorflow,6e298fa41fbc631d16bc25c3f3cb3cf19f20b4e8,Allan Renucci,2025-07-03T10:26:25Z,[XLA:GPU] Extract common pattern in combiner tests.  PiperOrigin-RevId: 778829151,57,125,182
tensorflow/tensorflow,8d0fb986190a8b88cd119b39978c9746d6235e94,Adrian Kuegel,2025-07-03T10:26:06Z,"[XLA:GPU] Implement upwards tile propagation for ConcatenateOp.  For now, only support constant expressions for bound.  PiperOrigin-RevId: 778829093",154,1,155
tensorflow/tensorflow,70719c44f22f1bee9b10f3974ca3a363eb41154c,Alexander Lyashuk,2025-07-03T10:12:31Z,[XLA] Add ShapeUtil::InsertDimensionAtIndex.  PiperOrigin-RevId: 778826054,75,4,79
tensorflow/tensorflow,e111faae1e5ef75b27df47dfe27c0af964bf10ed,Chun-nien Chan,2025-07-03T09:52:50Z,Add tfl-optimize pass  PiperOrigin-RevId: 778821518,14,3,17
tensorflow/tensorflow,a9231b76f067feb3e19b5668ae587caae2551860,Allan Renucci,2025-07-03T09:44:35Z,[XLA:GPU] Annotate module with suggested combiner threshold and use it in combiners.  Now both pipelined and synchronous collective combining is controlled via `--xla_gpu_experimental_enable_heuristic_collective_combining`.  PiperOrigin-RevId: 778819204,383,482,865
tensorflow/tensorflow,c08da65d3e18d20604ac87001e25992e0d3a25c5,A. Unique TensorFlower,2025-07-03T09:42:46Z,Move expensive variables on their last use to avoid copies.  PiperOrigin-RevId: 778818762,3,2,5
tensorflow/tensorflow,27ecf9b5f4ed4395dd7d7818a8e75a43f739ad89,A. Unique TensorFlower,2025-07-03T09:02:55Z,compat: Update forward compatibility horizon to 2025-07-03  PiperOrigin-RevId: 778809156,1,1,2
tensorflow/tensorflow,724ca9c602da12d10036fb73f6797be33b41f39e,A. Unique TensorFlower,2025-07-03T09:02:45Z,Update GraphDef version to 2277.  PiperOrigin-RevId: 778809099,1,1,2
tensorflow/tensorflow,c1cee8d106be2fbac43e177d4f9a48b065e1941b,Theotime Combes,2025-07-03T08:56:59Z,[XLA:GPU] Add triton support test for sort  PiperOrigin-RevId: 778807724,51,2,53
tensorflow/tensorflow,9684bc71fa02c1421eb6e74ba62275ecf7a2afbd,Buddh Prakash,2025-07-03T08:54:40Z,"[HLO Diff] Replace usages of boost::bimap with a custom bidirectional map.  This removes XLA's dependency on Boost, which has caused issues in the past due to the unreliability of the fedora servers which are used to fetch boost's dependency. This also helps reduce HLO Diff's runtime by ~30% on one of largest HLO pairs.  PiperOrigin-RevId: 778807128",147,111,258
tensorflow/tensorflow,b23a5c5b4ca5d957e9d997cbd36c57a38751da04,Karlo Basioli,2025-07-03T08:52:41Z,[XLA:CPU][nanort] Store program shape in NanoRtExecutable.  PiperOrigin-RevId: 778806598,25,10,35
tensorflow/tensorflow,c496bba77ec6202e9261d7414e02f9aa6f0c710e,Mikhail Goncharov,2025-07-03T08:42:46Z,[XLA:GPU] nest gemm fusion test: separate tests that are parametrized on reshape op  We should not parametrize e.g. basic test as it does not have any bitcasts  PiperOrigin-RevId: 778804093,120,118,238
