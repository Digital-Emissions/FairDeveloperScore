#!/usr/bin/env python3
"""
Developer Profile EDA Analysis

åŸºäºç»“æ„åŒ–æ€è·¯åˆ†æå¼€å‘è€…è¡Œä¸ºç‰¹å¾ï¼Œæ¢ç´¢å“ªäº›è¡Œä¸ºæ¨¡å¼æ›´å®¹æ˜“å½¢æˆbatchèšç±»ã€‚

EDAæ€è·¯ï¼š
1. äº†è§£æ•°æ®ç»“æ„
2. æ„å»ºè¡Œä¸ºç‰¹å¾åˆ†æ
3. è¯†åˆ«batchèšç±»çš„å…³é”®æŒ‡æ ‡
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®å¯è§†åŒ–å‚æ•°
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

class DeveloperProfileAnalyzer:
    def __init__(self, csv_path):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.csv_path = csv_path
        self.df = None
        self.load_data()
        
    def load_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        print("æ­£åœ¨åŠ è½½å¼€å‘è€…æ¡£æ¡ˆæ•°æ®...")
        try:
            self.df = pd.read_csv(self.csv_path)
            
            # æ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹
            self.df = self.df.fillna(0)  # å¡«å……ç¼ºå¤±å€¼
            
            # åˆ›å»ºæ´¾ç”Ÿç‰¹å¾
            self.df['productivity_ratio'] = self.df['commit_count'] / (self.df['active_days'] + 1)  # é¿å…é™¤é›¶
            self.df['change_efficiency'] = self.df['avg_total_changes'] / (self.df['avg_msg_len'] + 1)
            self.df['pr_activity'] = self.df['total_prs'] > 0
            self.df['weekend_worker'] = self.df['weekend_commit_ratio'] > 0.2
            
            # å¼€å‘è€…ç±»å‹åˆ†ç±»
            self.df['developer_type'] = self.categorize_developers()
            
            print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸã€‚å½¢çŠ¶: {self.df.shape}")
            print(f"âœ“ å¼€å‘è€…æ•°é‡: {len(self.df)}")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½é”™è¯¯: {e}")
            
    def categorize_developers(self):
        """åŸºäºè¡Œä¸ºç‰¹å¾å¯¹å¼€å‘è€…è¿›è¡Œåˆ†ç±»"""
        categories = []
        for _, row in self.df.iterrows():
            if row['commit_count'] >= 10 and row['pr_acceptance_rate'] >= 0.8:
                categories.append('Core Contributor')
            elif row['commit_count'] >= 5:
                categories.append('Regular Contributor')
            elif row['total_prs'] > 0:
                categories.append('PR Contributor')
            else:
                categories.append('Occasional Contributor')
        return categories
    
    def understand_data_structure(self):
        """ç¬¬ä¸€æ­¥ï¼šäº†è§£æ•°æ®ç»“æ„"""
        print("\n" + "="*80)
        print("ç¬¬ä¸€æ­¥ï¼šæ•°æ®ç»“æ„åˆ†æ")
        print("="*80)
        
        print(f"æ•°æ®ç»´åº¦: {self.df.shape[0]} å¼€å‘è€… Ã— {self.df.shape[1]} ç‰¹å¾")
        print(f"\nå­—æ®µåˆ—è¡¨:")
        for i, col in enumerate(self.df.columns, 1):
            print(f"{i:2d}. {col}")
        
        print(f"\næ•°æ®ç±»å‹åˆ†å¸ƒ:")
        print(self.df.dtypes.value_counts())
        
        print(f"\nåŸºç¡€ç»Ÿè®¡ä¿¡æ¯:")
        print(self.df.describe())
        
        # è¯†åˆ«è¡Œä¸ºç‰¹å¾ vs ç»“æœå˜é‡
        behavior_features = {
            'æ—¶é—´ç›¸å…³': ['active_days', 'weekend_commit_ratio'],
            'å†…å®¹ç›¸å…³': ['avg_additions', 'avg_deletions', 'avg_total_changes', 'max_total_changes', 'avg_msg_len'],
            'å¼€å‘è€…ç›¸å…³': ['commit_count', 'total_prs', 'merged_prs', 'pr_acceptance_rate'],
            'ç”Ÿäº§åŠ›æŒ‡æ ‡': ['productivity_ratio', 'change_efficiency']
        }
        
        print(f"\nè¡Œä¸ºç‰¹å¾åˆ†ç±»:")
        for category, features in behavior_features.items():
            print(f"  {category}: {features}")
    
    def analyze_behavioral_features(self):
        """ç¬¬äºŒæ­¥ï¼šæ„å»ºè¡Œä¸ºç‰¹å¾åˆ†æ"""
        print("\n" + "="*80)
        print("ç¬¬äºŒæ­¥ï¼šè¡Œä¸ºç‰¹å¾åˆ†æ")
        print("="*80)
        
        # åˆ›å»ºå¤šä¸ªå­å›¾
        fig, axes = plt.subplots(3, 2, figsize=(15, 18))
        
        # 1. æ—¶é—´ç›¸å…³ç‰¹å¾
        axes[0, 0].hist(self.df['active_days'], bins=30, alpha=0.7, color='skyblue')
        axes[0, 0].set_title('Distribution of Active Days')
        axes[0, 0].set_xlabel('Active Days')
        axes[0, 0].set_ylabel('Number of Developers')
        
        axes[0, 1].hist(self.df['weekend_commit_ratio'], bins=20, alpha=0.7, color='lightcoral')
        axes[0, 1].set_title('Weekend Commit Ratio Distribution')
        axes[0, 1].set_xlabel('Weekend Commit Ratio')
        axes[0, 1].set_ylabel('Number of Developers')
        
        # 2. å†…å®¹ç›¸å…³ç‰¹å¾
        axes[1, 0].scatter(self.df['avg_total_changes'], self.df['avg_msg_len'], alpha=0.6)
        axes[1, 0].set_title('Code Changes vs Message Length')
        axes[1, 0].set_xlabel('Average Total Changes')
        axes[1, 0].set_ylabel('Average Message Length')
        axes[1, 0].set_xscale('log')
        axes[1, 0].set_yscale('log')
        
        # 3. å¼€å‘è€…æ´»è·ƒåº¦
        commit_bins = [0, 1, 5, 10, 50, float('inf')]
        commit_labels = ['1', '2-5', '6-10', '11-50', '50+']
        self.df['commit_category'] = pd.cut(self.df['commit_count'], bins=commit_bins, labels=commit_labels)
        
        commit_dist = self.df['commit_category'].value_counts()
        axes[1, 1].pie(commit_dist.values, labels=commit_dist.index, autopct='%1.1f%%')
        axes[1, 1].set_title('Developer Activity Distribution')
        
        # 4. PRç›¸å…³ç‰¹å¾
        pr_active = self.df[self.df['total_prs'] > 0]
        if len(pr_active) > 0:
            axes[2, 0].scatter(pr_active['total_prs'], pr_active['pr_acceptance_rate'], alpha=0.6)
            axes[2, 0].set_title('PR Volume vs Acceptance Rate')
            axes[2, 0].set_xlabel('Total PRs')
            axes[2, 0].set_ylabel('PR Acceptance Rate')
        
        # 5. å¼€å‘è€…ç±»å‹åˆ†å¸ƒ
        dev_type_counts = self.df['developer_type'].value_counts()
        axes[2, 1].barh(range(len(dev_type_counts)), dev_type_counts.values)
        axes[2, 1].set_yticks(range(len(dev_type_counts)))
        axes[2, 1].set_yticklabels(dev_type_counts.index)
        axes[2, 1].set_title('Developer Type Distribution')
        axes[2, 1].set_xlabel('Number of Developers')
        
        plt.tight_layout()
        plt.savefig('developer_profile_behavioral_features.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ è¡Œä¸ºç‰¹å¾åˆ†æå®Œæˆ - developer_profile_behavioral_features.png å·²ä¿å­˜")
    
    def analyze_batch_potential_indicators(self):
        """åˆ†ææ½œåœ¨çš„batchèšç±»æŒ‡æ ‡"""
        print("\n" + "="*80)
        print("ç¬¬ä¸‰æ­¥ï¼šBatchèšç±»æ½œåŠ›åˆ†æ")
        print("="*80)
        
        # å®šä¹‰å¯èƒ½å½±å“batchèšç±»çš„å…³é”®æŒ‡æ ‡
        
        # 1. é«˜é¢‘ç‡æäº¤è€…ï¼ˆæ›´å¯èƒ½æœ‰è¿ç»­çš„batchï¼‰
        high_frequency = self.df['productivity_ratio'] > self.df['productivity_ratio'].quantile(0.75)
        
        # 2. å°ç²’åº¦æäº¤è€…ï¼ˆæ›´å¯èƒ½æœ‰ç›¸å…³çš„å°commitsï¼‰
        small_changes = self.df['avg_total_changes'] < self.df['avg_total_changes'].quantile(0.5)
        
        # 3. æ´»è·ƒPRç”¨æˆ·ï¼ˆæ›´å¯èƒ½æœ‰åä½œbatchï¼‰
        active_pr_users = (self.df['total_prs'] > 0) & (self.df['pr_acceptance_rate'] > 0.5)
        
        # 4. å‘¨æœ«å·¥ä½œè€…ï¼ˆå¯èƒ½æœ‰ä¸åŒçš„å·¥ä½œæ¨¡å¼ï¼‰
        weekend_workers = self.df['weekend_commit_ratio'] > 0.1
        
        print(f"é«˜é¢‘ç‡æäº¤è€…: {high_frequency.sum()} ({high_frequency.mean()*100:.1f}%)")
        print(f"å°ç²’åº¦æäº¤è€…: {small_changes.sum()} ({small_changes.mean()*100:.1f}%)")
        print(f"æ´»è·ƒPRç”¨æˆ·: {active_pr_users.sum()} ({active_pr_users.mean()*100:.1f}%)")
        print(f"å‘¨æœ«å·¥ä½œè€…: {weekend_workers.sum()} ({weekend_workers.mean()*100:.1f}%)")
        
        # åˆ›å»ºbatchæ½œåŠ›è¯„åˆ†
        batch_score = (
            high_frequency.astype(int) * 2 +  # é«˜é¢‘ç‡æƒé‡æ›´é«˜
            small_changes.astype(int) +
            active_pr_users.astype(int) +
            weekend_workers.astype(int)
        )
        
        self.df['batch_potential_score'] = batch_score
        
        # å¯è§†åŒ–batchæ½œåŠ›åˆ†æ
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # Batchæ½œåŠ›è¯„åˆ†åˆ†å¸ƒ
        axes[0, 0].hist(batch_score, bins=range(6), alpha=0.7, align='left')
        axes[0, 0].set_title('Batch Potential Score Distribution')
        axes[0, 0].set_xlabel('Batch Score (0-5)')
        axes[0, 0].set_ylabel('Number of Developers')
        axes[0, 0].set_xticks(range(5))
        
        # ç”Ÿäº§åŠ› vs å˜æ›´å¤§å°
        scatter = axes[0, 1].scatter(self.df['productivity_ratio'], self.df['avg_total_changes'], 
                                   c=batch_score, cmap='viridis', alpha=0.6)
        axes[0, 1].set_title('Productivity vs Change Size (colored by batch score)')
        axes[0, 1].set_xlabel('Productivity Ratio')
        axes[0, 1].set_ylabel('Average Total Changes')
        axes[0, 1].set_yscale('log')
        plt.colorbar(scatter, ax=axes[0, 1])
        
        # å¼€å‘è€…ç±»å‹çš„batchæ½œåŠ›
        batch_by_type = self.df.groupby('developer_type')['batch_potential_score'].mean()
        axes[1, 0].bar(range(len(batch_by_type)), batch_by_type.values)
        axes[1, 0].set_xticks(range(len(batch_by_type)))
        axes[1, 0].set_xticklabels(batch_by_type.index, rotation=45)
        axes[1, 0].set_title('Average Batch Score by Developer Type')
        axes[1, 0].set_ylabel('Average Batch Score')
        
        # æ´»è·ƒåº¦ vs PRæˆåŠŸç‡
        pr_users = self.df[self.df['total_prs'] > 0]
        if len(pr_users) > 0:
            axes[1, 1].scatter(pr_users['commit_count'], pr_users['pr_acceptance_rate'], 
                             c=pr_users['batch_potential_score'], cmap='plasma', alpha=0.6)
            axes[1, 1].set_title('Commit Activity vs PR Success (colored by batch score)')
            axes[1, 1].set_xlabel('Commit Count')
            axes[1, 1].set_ylabel('PR Acceptance Rate')
        
        plt.tight_layout()
        plt.savefig('developer_profile_batch_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ Batchèšç±»åˆ†æå®Œæˆ - developer_profile_batch_analysis.png å·²ä¿å­˜")
        
        # åˆ†æé«˜æ½œåŠ›å¼€å‘è€…
        high_potential = self.df[batch_score >= 3]
        print(f"\né«˜batchæ½œåŠ›å¼€å‘è€… (score â‰¥3): {len(high_potential)} ({len(high_potential)/len(self.df)*100:.1f}%)")
        
        if len(high_potential) > 0:
            print("\né«˜æ½œåŠ›å¼€å‘è€…ç‰¹å¾:")
            print(high_potential[['author_login', 'developer_type', 'commit_count', 
                                'avg_total_changes', 'pr_acceptance_rate', 'batch_potential_score']].head(10))
    
    def correlation_and_feature_importance(self):
        """ç›¸å…³æ€§åˆ†æå’Œç‰¹å¾é‡è¦æ€§"""
        print("\n" + "="*80)
        print("ç¬¬å››æ­¥ï¼šç‰¹å¾ç›¸å…³æ€§åˆ†æ")
        print("="*80)
        
        # é€‰æ‹©æ•°å€¼ç‰¹å¾è¿›è¡Œç›¸å…³æ€§åˆ†æ
        numerical_features = [
            'commit_count', 'active_days', 'avg_additions', 'avg_deletions', 
            'avg_total_changes', 'max_total_changes', 'avg_msg_len',
            'weekend_commit_ratio', 'total_prs', 'pr_acceptance_rate',
            'productivity_ratio', 'change_efficiency', 'batch_potential_score'
        ]
        
        correlation_matrix = self.df[numerical_features].corr()
        
        # åˆ›å»ºç›¸å…³æ€§çƒ­åŠ›å›¾
        plt.figure(figsize=(14, 12))
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
                   square=True, linewidths=0.5, cbar_kws={"shrink": .8})
        plt.title('Developer Profile Feature Correlation Matrix')
        plt.tight_layout()
        plt.savefig('developer_profile_correlation_matrix.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        # å¯»æ‰¾ä¸batchæ½œåŠ›ç›¸å…³æ€§æœ€å¼ºçš„ç‰¹å¾
        batch_correlations = correlation_matrix['batch_potential_score'].abs().sort_values(ascending=False)
        print("\nä¸Batchæ½œåŠ›ç›¸å…³æ€§æœ€å¼ºçš„ç‰¹å¾:")
        for feature, corr in batch_correlations.head(8).items():
            if feature != 'batch_potential_score':
                print(f"  {feature}: {corr:.3f}")
        
        print("âœ“ ç›¸å…³æ€§åˆ†æå®Œæˆ - developer_profile_correlation_matrix.png å·²ä¿å­˜")
    
    def generate_insights_and_recommendations(self):
        """ç”Ÿæˆæ´å¯Ÿå’Œå»ºè®®"""
        print("\n" + "="*80)
        print("ç¬¬äº”æ­¥ï¼šæ´å¯Ÿæ€»ç»“å’ŒTorque Clusteringå»ºè®®")
        print("="*80)
        
        # è®¡ç®—å…³é”®ç»Ÿè®¡æ•°æ®
        high_productivity = self.df['productivity_ratio'].quantile(0.8)
        avg_batch_score = self.df['batch_potential_score'].mean()
        
        print("å…³é”®å‘ç°:")
        print(f"1. å¼€å‘è€…ç±»å‹åˆ†å¸ƒ:")
        for dev_type, count in self.df['developer_type'].value_counts().items():
            pct = count / len(self.df) * 100
            print(f"   - {dev_type}: {count} ({pct:.1f}%)")
        
        print(f"\n2. è¡Œä¸ºç‰¹å¾æ´å¯Ÿ:")
        print(f"   - é«˜ç”Ÿäº§åŠ›é˜ˆå€¼ (80th percentile): {high_productivity:.2f} commits/day")
        print(f"   - å¹³å‡batchæ½œåŠ›è¯„åˆ†: {avg_batch_score:.2f}")
        print(f"   - å‘¨æœ«å·¥ä½œè€…æ¯”ä¾‹: {(self.df['weekend_commit_ratio'] > 0.1).mean()*100:.1f}%")
        print(f"   - æœ‰PRæ´»åŠ¨çš„å¼€å‘è€…: {(self.df['total_prs'] > 0).mean()*100:.1f}%")
        
        print(f"\n3. Torque Clusteringä¼˜åŒ–å»ºè®®:")
        
        # åŸºäºå¼€å‘è€…ç±»å‹çš„å»ºè®®
        core_contributors = self.df[self.df['developer_type'] == 'Core Contributor']
        if len(core_contributors) > 0:
            print(f"   - Core Contributorç‰¹å¾: å¹³å‡ {core_contributors['commit_count'].mean():.1f} commits, "
                  f"{core_contributors['avg_total_changes'].mean():.1f} lines/commit")
            print(f"     å»ºè®®: å¯¹æ ¸å¿ƒè´¡çŒ®è€…ä½¿ç”¨æ›´çŸ­çš„æ—¶é—´çª—å£ (15-30åˆ†é’Ÿ)")
        
        occasional = self.df[self.df['developer_type'] == 'Occasional Contributor']
        if len(occasional) > 0:
            print(f"   - Occasional Contributorç‰¹å¾: å¹³å‡ {occasional['commit_count'].mean():.1f} commits")
            print(f"     å»ºè®®: å¯¹å¶å‘è´¡çŒ®è€…ä½¿ç”¨æ›´é•¿çš„æ—¶é—´çª—å£ (2-4å°æ—¶)")
        
        # åŸºäºbatchæ½œåŠ›çš„å»ºè®®
        high_batch_potential = self.df[self.df['batch_potential_score'] >= 3]
        if len(high_batch_potential) > 0:
            avg_changes = high_batch_potential['avg_total_changes'].mean()
            avg_productivity = high_batch_potential['productivity_ratio'].mean()
            print(f"   - é«˜batchæ½œåŠ›å¼€å‘è€…: å¹³å‡ {avg_changes:.1f} lines/commit, "
                  f"ç”Ÿäº§åŠ› {avg_productivity:.2f}")
            print(f"     å»ºè®®: å¯¹è¿™ç±»å¼€å‘è€…çš„å°å˜æ›´ (<{avg_changes:.0f} lines) ä½¿ç”¨ç´§å¯†èšç±»")
        
        print(f"\n4. ç‰¹å¾æƒé‡å»ºè®®:")
        # åªé€‰æ‹©æ•°å€¼åˆ—è¿›è¡Œç›¸å…³æ€§åˆ†æ
        numerical_cols = self.df.select_dtypes(include=[np.number]).columns
        batch_corr = self.df[numerical_cols].corr()['batch_potential_score'].abs().sort_values(ascending=False)
        top_features = batch_corr.head(4).index.tolist()
        if 'batch_potential_score' in top_features:
            top_features.remove('batch_potential_score')
        print(f"   - å…³é”®ç‰¹å¾: {', '.join(top_features[:3])}")
        print(f"   - å»ºè®®åœ¨Torqueç®—æ³•ä¸­å¢åŠ è¿™äº›ç‰¹å¾çš„æƒé‡")
    
    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´çš„EDAåˆ†æ"""
        print("ğŸš€ å¼€å§‹å¼€å‘è€…æ¡£æ¡ˆEDAåˆ†æ...")
        print("åŸºäºç»“æ„åŒ–æ€è·¯æ¢ç´¢batchèšç±»çš„å…³é”®è¡Œä¸ºç‰¹å¾\n")
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šäº†è§£æ•°æ®ç»“æ„
            self.understand_data_structure()
            
            # ç¬¬äºŒæ­¥ï¼šè¡Œä¸ºç‰¹å¾åˆ†æ
            self.analyze_behavioral_features()
            
            # ç¬¬ä¸‰æ­¥ï¼šbatchèšç±»æ½œåŠ›åˆ†æ
            self.analyze_batch_potential_indicators()
            
            # ç¬¬å››æ­¥ï¼šç›¸å…³æ€§åˆ†æ
            self.correlation_and_feature_importance()
            
            # ç¬¬äº”æ­¥ï¼šæ´å¯Ÿå’Œå»ºè®®
            self.generate_insights_and_recommendations()
            
            print("\n" + "="*80)
            print("ğŸ‰ åˆ†æå®Œæˆ!")
            print("="*80)
            print("ç”Ÿæˆçš„å¯è§†åŒ–æ–‡ä»¶:")
            print("âœ“ developer_profile_behavioral_features.png")
            print("âœ“ developer_profile_batch_analysis.png")
            print("âœ“ developer_profile_correlation_matrix.png")
            
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

# ä¸»ç¨‹åºæ‰§è¡Œ
if __name__ == "__main__":
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = DeveloperProfileAnalyzer('data/developer_profile_final/merged_developer_profile_cleaned.csv')
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    analyzer.run_full_analysis() 